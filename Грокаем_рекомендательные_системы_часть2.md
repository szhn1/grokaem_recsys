# Грокаем рекомендательные системы: Часть 2

## Содержание
1. [Нейросетевые подходы в рекомендательных системах](#нейросетевые-подходы-в-рекомендательных-системах)
2. [Масштабирование рекомендательных систем для промышленного использования](#масштабирование-рекомендательных-систем-для-промышленного-использования)
3. [Решение проблемы холодного старта](#решение-проблемы-холодного-старта) 
4. [Контекстные рекомендации](#контекстные-рекомендации)
5. [Рекомендации с мультимодальными данными](#рекомендации-с-мультимодальными-данными)
6. [Многорукие бандиты и проблема исследования-использования](#многорукие-бандиты-и-проблема-исследования-использования)
7. [Оценка рекомендательных систем в реальном мире](#оценка-рекомендательных-систем-в-реальном-мире)
8. [Деплой рекомендательных систем](#деплой-рекомендательных-систем)
   - [Пример: Бесконечная лента рекомендаций в стиле TikTok](#пример-бесконечная-лента-рекомендаций-в-стиле-tiktok)
   - [Пример: Система рекомендаций в стиле Tinder](#пример-система-рекомендаций-в-стиле-tinder)
9. [Этические аспекты рекомендательных систем](#этические-аспекты-рекомендательных-систем)

## Нейросетевые подходы в рекомендательных системах

### Введение в нейросетевые рекомендательные системы

Если в первой части мы рассмотрели классические подходы к рекомендательным системам, то теперь настало время погрузиться в мир нейронных сетей. За последние годы глубокое обучение произвело революцию в рекомендательных системах, позволяя создавать более точные, гибкие и персонализированные рекомендации.

Представь, что мы хотим предсказать не просто оценку пользователя для фильма, но учесть при этом последовательность его действий, контекст, содержание фильма (изображения, описание) и многое другое. Классические методы с этим справляются плохо, а вот нейронные сети – отлично!

### Преимущества нейронных сетей в рекомендациях

1. **Способность работать с разнородными данными**: текст, изображения, последовательности действий
2. **Автоматическое извлечение признаков**: не нужно вручную проектировать признаки
3. **Нелинейные зависимости**: могут улавливать сложные паттерны в данных
4. **Масштабируемость**: современные нейросетевые архитектуры хорошо работают с большими данными

### Основные типы нейросетевых рекомендательных систем

#### 1. Neural Collaborative Filtering (NCF)

Neural Collaborative Filtering – это нейросетевой подход, который расширяет классическую матричную факторизацию. Вместо простого скалярного произведения векторов пользователя и предмета, NCF использует нейронную сеть для моделирования более сложных взаимодействий.

**Как это работает простыми словами:**
1. Каждый пользователь и предмет представляются векторами (эмбеддингами)
2. Эти векторы подаются на вход нейронной сети
3. Нейронная сеть обучается предсказывать вероятность взаимодействия пользователя с предметом

**Простая реализация NCF:**

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense
from tensorflow.keras.models import Model

def create_ncf_model(num_users, num_items, embedding_size=50):
    # Входные слои для ID пользователя и предмета
    user_input = Input(shape=(1,), name='user_input')
    item_input = Input(shape=(1,), name='item_input')
    
    # Эмбеддинги пользователей и предметов
    user_embedding = Embedding(num_users, embedding_size, name='user_embedding')(user_input)
    item_embedding = Embedding(num_items, embedding_size, name='item_embedding')(item_input)
    
    # Преобразуем эмбеддинги в плоские векторы
    user_vector = Flatten()(user_embedding)
    item_vector = Flatten()(item_embedding)
    
    # Объединяем векторы пользователя и предмета
    concat = Concatenate()([user_vector, item_vector])
    
    # Полносвязные слои для моделирования взаимодействий
    fc1 = Dense(128, activation='relu')(concat)
    fc2 = Dense(64, activation='relu')(fc1)
    output = Dense(1, activation='sigmoid')(fc2)
    
    # Создаем и компилируем модель
    model = Model(inputs=[user_input, item_input], outputs=output)
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# Пример использования
num_users = 1000
num_items = 2000
model = create_ncf_model(num_users, num_items)
model.summary()
```

**Математическое обоснование:**
В классической матричной факторизации, оценка предсказывается как:
$\hat{y}_{ui} = p_u^T q_i$, где $p_u$ - вектор пользователя, $q_i$ - вектор предмета.

В NCF это преобразуется в:
$\hat{y}_{ui} = f(p_u, q_i | \Theta)$, где $f$ - нейронная сеть с параметрами $\Theta$.

#### 2. Wide & Deep модели

Модель Wide & Deep, разработанная Google, объединяет линейную ("широкую") модель и глубокую нейронную сеть для рекомендаций. "Широкая" часть хорошо запоминает конкретные взаимодействия, а "глубокая" часть обеспечивает обобщение.

**Как это работает простыми словами:**
1. Широкая часть: линейная модель, которая хорошо запоминает конкретные взаимодействия (пользователь A любит фильм X)
2. Глубокая часть: нейронная сеть, которая находит скрытые паттерны (пользователи, похожие на A, любят фильмы, похожие на X)
3. Результаты объединяются для финального предсказания

**Реализация Wide & Deep модели:**

```python
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense
from tensorflow.keras.models import Model

def create_wide_and_deep_model(num_users, num_items, embedding_size=50):
    # Входные слои
    user_input = Input(shape=(1,), name='user_input')
    item_input = Input(shape=(1,), name='item_input')
    
    # Широкая часть (линейная)
    wide_user_embedding = Embedding(num_users, 1, name='wide_user_embedding')(user_input)
    wide_item_embedding = Embedding(num_items, 1, name='wide_item_embedding')(item_input)
    
    wide_user = Flatten()(wide_user_embedding)
    wide_item = Flatten()(wide_item_embedding)
    wide_output = Concatenate()([wide_user, wide_item])
    
    # Глубокая часть (нейронная сеть)
    deep_user_embedding = Embedding(num_users, embedding_size, name='deep_user_embedding')(user_input)
    deep_item_embedding = Embedding(num_items, embedding_size, name='deep_item_embedding')(item_input)
    
    deep_user = Flatten()(deep_user_embedding)
    deep_item = Flatten()(deep_item_embedding)
    deep_concat = Concatenate()([deep_user, deep_item])
    
    deep_1 = Dense(128, activation='relu')(deep_concat)
    deep_2 = Dense(64, activation='relu')(deep_1)
    deep_output = Dense(1, activation='linear')(deep_2)
    
    # Объединяем широкую и глубокую части
    output = Concatenate()([wide_output, deep_output])
    output = Dense(1, activation='sigmoid')(output)
    
    model = Model(inputs=[user_input, item_input], outputs=output)
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

#### 3. Последовательные (sequential) рекомендации с RNN и Transformer

Для многих задач важно учитывать последовательность действий пользователя. Например, то, что человек смотрел вчера, сильно влияет на то, что он захочет посмотреть сегодня. Для этого используются рекуррентные нейронные сети (RNN) и трансформеры.

**Как это работает простыми словами:**
1. Берем историю действий пользователя как последовательность предметов
2. Пропускаем через RNN или Transformer
3. Получаем предсказание следующего предмета в последовательности

**Пример реализации с LSTM (тип RNN):**

```python
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense
from tensorflow.keras.models import Model

def create_sequence_model(num_items, max_sequence_length, embedding_size=50):
    # Входной слой для последовательности предметов
    sequence_input = Input(shape=(max_sequence_length,), name='sequence_input')
    
    # Эмбеддинг предметов
    item_embedding = Embedding(num_items + 1, embedding_size, mask_zero=True, name='item_embedding')(sequence_input)
    
    # LSTM для обработки последовательности
    lstm_output = LSTM(128)(item_embedding)
    
    # Полносвязные слои
    fc = Dense(64, activation='relu')(lstm_output)
    
    # Выходной слой: вероятности для каждого предмета
    output = Dense(num_items, activation='softmax')(fc)
    
    model = Model(inputs=sequence_input, outputs=output)
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

**Пример с Transformer (современный подход):**

```python
from tensorflow.keras.layers import Input, Embedding, Dense, MultiHeadAttention, LayerNormalization, Dropout
from tensorflow.keras.models import Model

def transformer_block(inputs, head_size, num_heads, ff_dim, dropout=0):
    # Мульти-головое внимание
    attention_output = MultiHeadAttention(
        num_heads=num_heads, key_dim=head_size
    )(inputs, inputs)
    attention_output = Dropout(dropout)(attention_output)
    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)
    
    # Полносвязный блок
    ffn_output = Dense(ff_dim, activation='relu')(attention_output)
    ffn_output = Dense(inputs.shape[-1])(ffn_output)
    ffn_output = Dropout(dropout)(ffn_output)
    
    return LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)

def create_transformer_model(num_items, max_sequence_length, embedding_size=50):
    # Входной слой
    sequence_input = Input(shape=(max_sequence_length,))
    
    # Эмбеддинг предметов
    embedding_layer = Embedding(num_items + 1, embedding_size, mask_zero=True)(sequence_input)
    
    # Трансформер-блок
    transformer_output = transformer_block(
        embedding_layer, 
        head_size=32, 
        num_heads=4, 
        ff_dim=256
    )
    
    # Берем только последний элемент последовательности
    last_item_output = transformer_output[:, -1, :]
    
    # Финальный слой
    output = Dense(num_items, activation='softmax')(last_item_output)
    
    model = Model(inputs=sequence_input, outputs=output)
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

### Современная архитектура: BERT4Rec

BERT4Rec – это рекомендательная система на основе архитектуры BERT (Bidirectional Encoder Representations from Transformers), которая стала революцией в области обработки естественного языка. В BERT4Rec последовательность взаимодействий пользователя рассматривается как "предложение", а каждое взаимодействие – как "слово".

**Как это работает простыми словами:**
1. Мы маскируем случайные взаимодействия в истории пользователя
2. Обучаем модель предсказывать эти замаскированные взаимодействия
3. При рекомендации маскируем последнее взаимодействие и предсказываем его

**Пример упрощенной реализации BERT4Rec:**

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout
from tensorflow.keras.models import Model

def bert_encoder_block(inputs, hidden_size, num_heads, dropout_rate=0.1):
    # Мульти-головое внимание
    attention_output = tf.keras.layers.MultiHeadAttention(
        num_heads=num_heads, key_dim=hidden_size // num_heads
    )(inputs, inputs, attention_mask=None)
    attention_output = Dropout(dropout_rate)(attention_output)
    attention_output = LayerNormalization(epsilon=1e-6)(inputs + attention_output)
    
    # Feed-forward сеть
    ffn = Dense(hidden_size * 4, activation='gelu')(attention_output)
    ffn_output = Dense(hidden_size)(ffn)
    ffn_output = Dropout(dropout_rate)(ffn_output)
    
    return LayerNormalization(epsilon=1e-6)(attention_output + ffn_output)

def create_bert4rec_model(num_items, max_sequence_length, hidden_size=256, num_blocks=2, num_heads=4):
    # Входные слои
    sequence_input = Input(shape=(max_sequence_length,), dtype=tf.int32, name='sequence_input')
    
    # Эмбеддинг предметов и позиций
    item_embedding = Embedding(num_items + 2, hidden_size)(sequence_input)  # +2 для [MASK] и [PAD]
    position_embedding = Embedding(max_sequence_length, hidden_size)(
        tf.range(start=0, limit=max_sequence_length, delta=1)
    )
    
    # Объединяем эмбеддинги
    embedded_input = item_embedding + position_embedding
    
    # Блоки BERT кодировщика
    encoder_output = embedded_input
    for _ in range(num_blocks):
        encoder_output = bert_encoder_block(
            encoder_output, hidden_size, num_heads
        )
    
    # Выходной слой для предсказания замаскированных токенов
    output = Dense(num_items + 1, activation='softmax')(encoder_output)
    
    model = Model(inputs=sequence_input, outputs=output)
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

### Задание №1: Обучение простой модели Neural Collaborative Filtering

Давай создадим и обучим простую модель Neural Collaborative Filtering на синтетических данных:

```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import seaborn as sns

# Создаем синтетический датасет
np.random.seed(42)
num_users = 1000
num_items = 500
num_interactions = 20000

# Генерируем случайные взаимодействия
user_ids = np.random.randint(0, num_users, num_interactions)
item_ids = np.random.randint(0, num_items, num_interactions)

# Генерируем целевую переменную (1 - пользователю понравилось, 0 - не понравилось)
# В реальном примере это может быть лайк, просмотр до конца и т.д.
labels = np.random.binomial(1, 0.7, num_interactions)  # 70% положительных взаимодействий

# Создаем DataFrame
data = pd.DataFrame({
    'user_id': user_ids,
    'item_id': item_ids,
    'interaction': labels
})

# Разделяем данные на обучающую и валидационную выборки
from sklearn.model_selection import train_test_split
train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)

# Создаем модель NCF
def create_ncf_model(num_users, num_items, embedding_size=30):
    # Входные слои
    user_input = Input(shape=(1,), name='user_input')
    item_input = Input(shape=(1,), name='item_input')
    
    # Эмбеддинги
    user_embedding = Embedding(num_users, embedding_size, name='user_embedding')(user_input)
    item_embedding = Embedding(num_items, embedding_size, name='item_embedding')(item_input)
    
    # Сглаживаем эмбеддинги
    user_vector = Flatten()(user_embedding)
    item_vector = Flatten()(item_embedding)
    
    # Конкатенируем векторы
    concat = Concatenate()([user_vector, item_vector])
    
    # Полносвязные слои
    fc1 = Dense(64, activation='relu')(concat)
    fc2 = Dense(32, activation='relu')(fc1)
    output = Dense(1, activation='sigmoid', name='output')(fc2)
    
    # Создаем модель
    model = Model(inputs=[user_input, item_input], outputs=output)
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model

# Создаем и обучаем модель
model = create_ncf_model(num_users, num_items)
model.summary()

# Подготавливаем данные для обучения
X_train = [train_data['user_id'].values, train_data['item_id'].values]
y_train = train_data['interaction'].values

X_val = [val_data['user_id'].values, val_data['item_id'].values]
y_val = val_data['interaction'].values

# Обучаем модель
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=5,
    batch_size=64,
    verbose=1
)

# Визуализируем процесс обучения
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Обучающая выборка')
plt.plot(history.history['val_loss'], label='Валидационная выборка')
plt.title('Функция потерь')
plt.xlabel('Эпоха')
plt.ylabel('Потери')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Обучающая выборка')
plt.plot(history.history['val_accuracy'], label='Валидационная выборка')
plt.title('Точность')
plt.xlabel('Эпоха')
plt.ylabel('Точность')
plt.legend()

plt.tight_layout()
plt.show()

# Получаем рекомендации для пользователя
def get_recommendations(user_id, num_recommendations=5):
    # Создаем список всех предметов
    all_items = np.arange(num_items)
    
    # Получаем предсказания модели
    user_input = np.full(num_items, user_id)
    predictions = model.predict([user_input, all_items], verbose=0).flatten()
    
    # Получаем предметы, которые пользователь уже оценил
    user_interactions = data[data['user_id'] == user_id]['item_id'].values
    
    # Исключаем предметы, которые пользователь уже взаимодействовал
    mask = np.ones(num_items, dtype=bool)
    mask[user_interactions] = False
    valid_items = all_items[mask]
    valid_predictions = predictions[mask]
    
    # Сортируем предметы по предсказанной вероятности
    top_indices = np.argsort(-valid_predictions)[:num_recommendations]
    recommended_items = valid_items[top_indices]
    
    return recommended_items, valid_predictions[top_indices]

# Получаем рекомендации для случайного пользователя
random_user = np.random.randint(0, num_users)
recommendations, scores = get_recommendations(random_user)

print(f"Рекомендации для пользователя {random_user}:")
for i, (item, score) in enumerate(zip(recommendations, scores), 1):
    print(f"{i}. Предмет {item}: {score:.4f}")
```

**Что нужно понять из этого задания:**
1. Как представить задачу рекомендаций в виде задачи бинарной классификации
2. Как создать простую нейросетевую модель для рекомендаций
3. Как обучить модель и получить рекомендации для конкретного пользователя

В следующих разделах мы рассмотрим более сложные нейросетевые архитектуры и методы их применения для рекомендательных систем. 

## Масштабирование рекомендательных систем для промышленного использования

### Проблемы масштабирования рекомендательных систем

Когда мы переходим от экспериментальных моделей к реальным промышленным системам, возникает много новых вызовов:

1. **Объемы данных**: миллионы или миллиарды пользователей и предметов
2. **Высокая нагрузка**: тысячи запросов в секунду
3. **Низкая задержка**: рекомендации должны генерироваться за миллисекунды
4. **Актуальность**: модели нужно постоянно обновлять новыми данными
5. **Ограниченные ресурсы**: нужно эффективно использовать доступное оборудование

### Стратегии масштабирования

#### 1. Двухуровневые архитектуры (Two-stage architectures)

Одна из самых популярных стратегий – использование двухуровневой архитектуры:

**Как это работает простыми словами:**
1. **Первый этап (Retrieval)**: быстро отбираем несколько сотен или тысяч кандидатов из миллионов возможных предметов
2. **Второй этап (Ranking)**: применяем более сложную модель, чтобы ранжировать этих кандидатов и показать лучшие

```
Пользователь → [Retrieval (отбор)] → [Ranking (ранжирование)] → Топ-N рекомендаций
```

**Преимущества:**
- Позволяет эффективно работать с миллионами предметов
- Комбинирует скорость простых алгоритмов и точность сложных
- Можно использовать разные подходы на разных этапах

**Пример упрощенной реализации:**

```python
import numpy as np
from sklearn.neighbors import NearestNeighbors
import tensorflow as tf

class TwoStageRecommender:
    def __init__(self, num_users, num_items, embedding_size=32):
        self.num_users = num_users
        self.num_items = num_items
        
        # Этап 1: Retrieval - используем простую матричную факторизацию
        # для быстрого извлечения кандидатов
        self.user_factors = np.random.normal(0, 0.1, (num_users, embedding_size))
        self.item_factors = np.random.normal(0, 0.1, (num_items, embedding_size))
        
        # Создаем индекс для быстрого поиска соседей
        self.item_index = NearestNeighbors(metric='cosine', algorithm='brute')
        self.item_index.fit(self.item_factors)
        
        # Этап 2: Ranking - используем более сложную нейронную сеть
        self.ranking_model = self._create_ranking_model(embedding_size)
    
    def _create_ranking_model(self, embedding_size):
        # Создаем более сложную модель для точного ранжирования
        user_input = tf.keras.layers.Input(shape=(1,))
        item_input = tf.keras.layers.Input(shape=(1,))
        
        # Используем предварительно обученные эмбеддинги
        user_embedding = tf.keras.layers.Embedding(
            self.num_users, embedding_size, 
            embeddings_initializer=tf.keras.initializers.Constant(self.user_factors),
            trainable=True
        )(user_input)
        
        item_embedding = tf.keras.layers.Embedding(
            self.num_items, embedding_size,
            embeddings_initializer=tf.keras.initializers.Constant(self.item_factors),
            trainable=True
        )(item_input)
        
        user_vector = tf.keras.layers.Flatten()(user_embedding)
        item_vector = tf.keras.layers.Flatten()(item_embedding)
        
        # Добавляем больше слоев для моделирования сложных взаимодействий
        concat = tf.keras.layers.Concatenate()([user_vector, item_vector])
        fc1 = tf.keras.layers.Dense(128, activation='relu')(concat)
        fc2 = tf.keras.layers.Dense(64, activation='relu')(fc1)
        fc3 = tf.keras.layers.Dense(32, activation='relu')(fc2)
        output = tf.keras.layers.Dense(1, activation='sigmoid')(fc3)
        
        model = tf.keras.models.Model(inputs=[user_input, item_input], outputs=output)
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def recommend(self, user_id, n_recommendations=10, n_candidates=100):
        """Двухуровневый процесс рекомендаций"""
        # Этап 1: Retrieval - быстрый отбор кандидатов
        user_vector = self.user_factors[user_id].reshape(1, -1)
        distances, candidate_indices = self.item_index.kneighbors(
            user_vector, n_neighbors=n_candidates
        )
        candidate_items = candidate_indices[0]
        
        # Этап 2: Ranking - точное ранжирование кандидатов
        user_ids = np.full(len(candidate_items), user_id)
        predictions = self.ranking_model.predict(
            [user_ids, candidate_items], verbose=0
        ).flatten()
        
        # Сортируем кандидатов по предсказанным оценкам
        top_indices = np.argsort(-predictions)[:n_recommendations]
        recommended_items = candidate_items[top_indices]
        
        return recommended_items, predictions[top_indices]
```

#### 2. Распределенные вычисления: Apache Spark

Для обработки больших объемов данных и обучения моделей на огромных датасетах часто используют Apache Spark.

**Как это работает простыми словами:**
1. Данные разделяются на части и обрабатываются параллельно на разных машинах
2. Spark автоматически управляет распределением задач и сбором результатов
3. Это позволяет масштабировать вычисления практически линейно с ростом кластера

**Пример использования Spark для матричной факторизации:**

```python
from pyspark.ml.recommendation import ALS
from pyspark.sql import SparkSession

# Создаем Spark-сессию
spark = SparkSession.builder \
    .appName("RecommendationSystem") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()

# Загружаем данные
ratings_df = spark.read.csv("hdfs://path/to/ratings.csv", header=True)
ratings_df = ratings_df.select(
    ratings_df.userId.cast("int"),
    ratings_df.movieId.cast("int"),
    ratings_df.rating.cast("float")
)

# Создаем и обучаем модель ALS
als = ALS(
    maxIter=10,
    regParam=0.1,
    userCol="userId",
    itemCol="movieId",
    ratingCol="rating",
    coldStartStrategy="drop",
    nonnegative=True
)

model = als.fit(ratings_df)

# Генерируем топ-10 рекомендаций для каждого пользователя
user_recs = model.recommendForAllUsers(10)

# Показываем рекомендации для первых 5 пользователей
user_recs.show(5)

# Сохраняем модель для последующего использования
model.save("hdfs://path/to/als_model")
```

#### 3. Эффективное обслуживание рекомендаций: векторные базы данных

Для быстрого поиска похожих предметов часто используются векторные базы данных, такие как Faiss (Facebook AI Similarity Search) или Milvus.

**Как это работает простыми словами:**
1. Предметы представляются в виде векторов (эмбеддингов)
2. Векторная база данных строит специальные индексы для быстрого поиска ближайших соседей
3. Когда нужно найти похожие предметы, мы ищем ближайшие векторы с помощью этих индексов

**Пример использования Faiss:**

```python
import numpy as np
import faiss

# Предположим, у нас есть эмбеддинги предметов
# В реальности они бы получались из обученной модели
n_items = 1000000  # 1 миллион предметов
d = 64  # размерность эмбеддингов
item_embeddings = np.random.random((n_items, d)).astype('float32')

# Нормализуем векторы для косинусного сходства
faiss.normalize_L2(item_embeddings)

# Создаем индекс Faiss
# IVF100 означает, что мы делим пространство на 100 кластеров
# PQ16 означает, что мы используем сжатие векторов для экономии памяти
index = faiss.index_factory(d, "IVF100,PQ16", faiss.METRIC_INNER_PRODUCT)

# Обучаем индекс (находим центры кластеров)
index.train(item_embeddings)

# Добавляем векторы в индекс
index.add(item_embeddings)

# Функция для быстрого поиска похожих предметов
def find_similar_items(item_id, top_k=10):
    # Получаем эмбеддинг предмета
    query_vector = item_embeddings[item_id].reshape(1, -1)
    
    # Находим похожие предметы
    distances, indices = index.search(query_vector, top_k + 1)  # +1, т.к. сам предмет тоже будет в результатах
    
    # Исключаем сам предмет из результатов
    if indices[0][0] == item_id:
        indices = indices[0][1:]
        distances = distances[0][1:]
    else:
        indices = indices[0][:top_k]
        distances = distances[0][:top_k]
    
    return list(zip(indices, distances))

# Пример использования
item_id = 42
similar_items = find_similar_items(item_id)
print(f"Предметы, похожие на {item_id}:")
for i, (similar_id, similarity) in enumerate(similar_items, 1):
    print(f"{i}. Предмет {similar_id}: сходство {similarity:.4f}")
```

#### 4. Инкрементное обучение и онлайн-обновления

В реальных системах данные постоянно обновляются, и модели должны быстро адаптироваться к новым паттернам.

**Инкрементное обучение простыми словами:**
1. Модель обучается постепенно, получая новые порции данных
2. Не требуется полное переобучение на всем датасете
3. Модель адаптируется к новым трендам и изменениям в поведении пользователей

**Пример инкрементного обучения:**

```python
from sklearn.linear_model import SGDRegressor
import numpy as np

class IncrementalMatrixFactorization:
    def __init__(self, n_users, n_items, n_factors=20, learning_rate=0.01):
        self.n_users = n_users
        self.n_items = n_items
        self.n_factors = n_factors
        
        # Инициализируем эмбеддинги пользователей и предметов
        self.user_embeddings = np.random.normal(0, 0.1, (n_users, n_factors))
        self.item_embeddings = np.random.normal(0, 0.1, (n_items, n_factors))
        
        # Создаем модели для онлайн-обучения каждого пользователя
        self.user_models = [
            SGDRegressor(
                loss='squared_error',
                learning_rate='constant',
                eta0=learning_rate,
                alpha=0.0001,
                warm_start=True  # Позволяет продолжать обучение с текущего состояния
            ) 
            for _ in range(n_users)
        ]
        
        # И для каждого предмета
        self.item_models = [
            SGDRegressor(
                loss='squared_error',
                learning_rate='constant',
                eta0=learning_rate,
                alpha=0.0001,
                warm_start=True
            ) 
            for _ in range(n_items)
        ]
    
    def update(self, user_id, item_id, rating):
        """Обновляем модель при новом взаимодействии"""
        # Обновляем эмбеддинг пользователя
        user_model = self.user_models[user_id]
        user_model.fit(
            self.item_embeddings[item_id].reshape(1, -1),
            np.array([rating])
        )
        self.user_embeddings[user_id] = user_model.coef_
        
        # Обновляем эмбеддинг предмета
        item_model = self.item_models[item_id]
        item_model.fit(
            self.user_embeddings[user_id].reshape(1, -1),
            np.array([rating])
        )
        self.item_embeddings[item_id] = item_model.coef_
    
    def predict(self, user_id, item_id):
        """Предсказываем оценку"""
        return np.dot(self.user_embeddings[user_id], self.item_embeddings[item_id])
    
    def get_recommendations(self, user_id, n=10):
        """Получаем рекомендации для пользователя"""
        # Вычисляем оценки для всех предметов
        predictions = np.dot(self.user_embeddings[user_id], self.item_embeddings.T)
        
        # Сортируем по убыванию предсказанных оценок
        top_indices = np.argsort(-predictions)[:n]
        
        return top_indices, predictions[top_indices]

# Пример использования
imf = IncrementalMatrixFactorization(1000, 500)

# Обновляем модель при каждом новом взаимодействии
user_id = 42
item_id = 123
rating = 5.0
imf.update(user_id, item_id, rating)

# Получаем рекомендации
recommended_items, scores = imf.get_recommendations(user_id, n=5)
print(f"Рекомендации для пользователя {user_id}:")
for i, (item, score) in enumerate(zip(recommended_items, scores), 1):
    print(f"{i}. Предмет {item}: {score:.4f}")
```

### Архитектура промышленной рекомендательной системы

Типичная архитектура рекомендательной системы в крупном сервисе выглядит примерно так:

```
Сбор данных:
  Логи пользователя → Kafka/Kinesis → Обработка событий → Хранилище данных (Hadoop/S3)

Обучение моделей:
  Хранилище данных → Spark/Distributed ML → Обученные модели → Модельное хранилище

Обслуживание рекомендаций:
  Пользовательский запрос → API → Retrieval модель → Ranking модель → Фильтрация/бизнес-логика → Рекомендации
```

#### Задание №2: Создание масштабируемой архитектуры рекомендательной системы

Давай разработаем архитектуру масштабируемой рекомендательной системы для онлайн-магазина:

```python
import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import time
import threading
import queue
import json

class RecommendationSystem:
    def __init__(self):
        """Рекомендательная система с масштабируемой архитектурой"""
        # Компонент 1: Хранилище данных
        self.events_queue = queue.Queue()  # Очередь для новых событий (имитация Kafka)
        self.user_item_matrix = None       # Матрица взаимодействий пользователь-предмет
        self.user_features = None          # Признаки пользователей
        self.item_features = None          # Признаки предметов
        
        # Компонент 2: Модельный слой
        self.retrieval_model = None        # Модель для быстрого отбора кандидатов
        self.ranking_model = None          # Модель для точного ранжирования
        
        # Компонент 3: Слой обслуживания
        self.item_index = None             # Индекс для быстрого поиска предметов (имитация Faiss)
        self.model_version = 0             # Версия модели
        self.last_update_time = 0          # Время последнего обновления
        
        # Запускаем фоновые процессы
        self._start_event_processor()
        self._start_model_updater()
    
    def _start_event_processor(self):
        """Запускает фоновый процесс обработки событий"""
        def event_processor():
            while True:
                try:
                    # Получаем новое событие из очереди
                    event = self.events_queue.get(timeout=1)
                    
                    # Обрабатываем событие
                    # (в реальности здесь был бы код обновления данных в хранилище)
                    print(f"Обработка события: {event}")
                    
                    # Отмечаем задачу как выполненную
                    self.events_queue.task_done()
                    
                except queue.Empty:
                    # Если очередь пуста, просто ждем
                    time.sleep(0.1)
        
        # Запускаем процесс в фоновом режиме
        thread = threading.Thread(target=event_processor, daemon=True)
        thread.start()
    
    def _start_model_updater(self):
        """Запускает фоновый процесс обновления моделей"""
        def model_updater():
            while True:
                # Проверяем, не пора ли обновить модель
                current_time = time.time()
                if current_time - self.last_update_time > 60:  # Обновляем каждую минуту
                    print("Обновление моделей...")
                    
                    # Здесь был бы код обновления моделей
                    self.model_version += 1
                    self.last_update_time = current_time
                    
                    print(f"Модели обновлены до версии {self.model_version}")
                
                # Ждем перед следующей проверкой
                time.sleep(5)
        
        # Запускаем процесс в фоновом режиме
        thread = threading.Thread(target=model_updater, daemon=True)
        thread.start()
    
    def track_event(self, user_id, item_id, event_type, timestamp=None, properties=None):
        """Отслеживает новое событие пользователя"""
        if timestamp is None:
            timestamp = int(time.time())
        
        event = {
            'user_id': user_id,
            'item_id': item_id,
            'event_type': event_type,
            'timestamp': timestamp,
            'properties': properties or {}
        }
        
        # Добавляем событие в очередь для обработки
        self.events_queue.put(event)
        
        return True
    
    def get_recommendations(self, user_id, n=10, context=None):
        """Получает рекомендации для пользователя"""
        # Имитация двухуровневой архитектуры
        
        # Этап 1: Retrieval - быстрый отбор кандидатов
        # (в реальности здесь был бы запрос к индексу Faiss или подобному)
        candidate_items = np.random.randint(0, 1000, 100)  # 100 случайных кандидатов для примера
        
        # Этап 2: Ranking - точное ранжирование кандидатов
        # (в реальности здесь был бы вызов ML-модели)
        scores = np.random.random(len(candidate_items))
        
        # Сортируем кандидатов по предсказанным оценкам
        top_indices = np.argsort(-scores)[:n]
        recommended_items = candidate_items[top_indices]
        recommended_scores = scores[top_indices]
        
        # Формируем результат
        recommendations = []
        for item, score in zip(recommended_items, recommended_scores):
            recommendations.append({
                'item_id': int(item),
                'score': float(score),
                'model_version': self.model_version
            })
        
        return recommendations

# Пример использования
recommender = RecommendationSystem()

# Отслеживаем событие: пользователь просмотрел товар
recommender.track_event(
    user_id=123,
    item_id=456,
    event_type='view',
    properties={'duration': 30}
)

# Получаем рекомендации для пользователя
recommendations = recommender.get_recommendations(user_id=123, n=5)
print("Рекомендации:")
for i, rec in enumerate(recommendations, 1):
    print(f"{i}. Товар {rec['item_id']}: {rec['score']:.4f}")

# Эмулируем работу системы некоторое время
print("\nЭмуляция работы системы в течение 5 секунд...")
for i in range(10):
    # Генерируем случайные события
    user_id = np.random.randint(1, 200)
    item_id = np.random.randint(1, 1000)
    event_type = np.random.choice(['view', 'add_to_cart', 'purchase'])
    
    recommender.track_event(user_id, item_id, event_type)
    
    # Небольшая пауза
    time.sleep(0.5)

# Получаем новые рекомендации после некоторого времени работы
recommendations = recommender.get_recommendations(user_id=123, n=5)
print("\nНовые рекомендации:")
for i, rec in enumerate(recommendations, 1):
    print(f"{i}. Товар {rec['item_id']}: {rec['score']:.4f} (модель v{rec['model_version']})")
```

**Что нужно понять из этого кода:**
1. Как архитектурно разделить сбор данных, обучение моделей и обслуживание рекомендаций
2. Как обрабатывать потоки событий в реальном времени
3. Как обновлять модели без остановки системы
4. Как реализовать двухуровневую архитектуру для масштабирования

## Решение проблемы холодного старта

Холодный старт – это проблема, когда новый пользователь или предмет не имеет достаточного количества данных для получения релевантных рекомендаций.

### Стратегии решения проблемы холодного старта

#### 1. Рекомендации на основе содержания

Этот подход использует информацию о пользователе или предмете для поиска похожих предметов или содержания.

**Примеры:**
- Рекомендации на основе жанров или тегов
- Рекомендации на основе содержания текста или изображений

#### 2. Коллаборативная фильтрация

Этот подход использует данные о взаимодействиях пользователей для поиска похожих предпочтений.

**Примеры:**
- Рекомендации на основе пользовательских рейтингов или оценок
- Рекомендации на основе поведения пользователей

#### 3. Совместное обучение

Этот подход использует данные о взаимодействиях пользователей для обучения модели, которая может предсказывать предпочтения для новых пользователей или предметов.

**Примеры:**
- Рекомендации на основе совместного обучения
- Рекомендации на основе совместного обучения с использованием глубоких нейронных сетей

#### 4. Рекомендации на основе социальных взаимодействий

Этот подход использует данные о социальных взаимодействиях пользователей для поиска похожих предпочтений или рекомендаций.

**Примеры:**
- Рекомендации на основе друзей или сообществ
- Рекомендации на основе социальных сетей

#### 5. Рекомендации на основе контекста

Этот подход использует данные о контексте взаимодействия пользователя с предметом для поиска релевантных рекомендаций.

**Примеры:**
- Рекомендации на основе времени или места взаимодействия
- Рекомендации на основе контекста текста или изображений

### Примеры решений проблемы холодного старта

#### 1. Рекомендации на основе содержания

```python
# Пример реализации рекомендаций на основе содержания
def content_based_recommendation(user_id, item_id):
    # Реализация на основе содержания
    pass

# Пример использования
recommended_items = content_based_recommendation(user_id, item_id)
```

#### 2. Коллаборативная фильтрация

```python
# Пример реализации коллаборативной фильтрации
def collaborative_filtering_recommendation(user_id, item_id):
    # Реализация на основе коллаборативной фильтрации
    pass

# Пример использования
recommended_items = collaborative_filtering_recommendation(user_id, item_id)
```

#### 3. Совместное обучение

```python
# Пример реализации совместного обучения
def joint_training_recommendation(user_id, item_id):
    # Реализация на основе совместного обучения
    pass

# Пример использования
recommended_items = joint_training_recommendation(user_id, item_id)
```

#### 4. Рекомендации на основе социальных взаимодействий

```python
# Пример реализации рекомендаций на основе социальных взаимодействий
def social_interaction_recommendation(user_id, item_id):
    # Реализация на основе социальных взаимодействий
    pass

# Пример использования
recommended_items = social_interaction_recommendation(user_id, item_id)
```

#### 5. Рекомендации на основе контекста

```python
# Пример реализации рекомендаций на основе контекста
def context_based_recommendation(user_id, item_id):
    # Реализация на основе контекста
    pass

# Пример использования
recommended_items = context_based_recommendation(user_id, item_id)
```

### Задание №3: Решение проблемы холодного старта

Давай решим проблему холодного старта для нового пользователя путем реализации гибридного подхода:

```python
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class ColdStartRecommender:
    def __init__(self, items_df, ratings_df=None):
        """
        Рекомендательная система с обработкой холодного старта
        
        Параметры:
        - items_df: DataFrame с информацией о предметах (item_id, category, description и т.д.)
        - ratings_df: DataFrame с оценками (user_id, item_id, rating)
        """
        self.items_df = items_df
        self.ratings_df = ratings_df
        
        # Создаем TF-IDF векторы для описаний предметов
        self.tfidf = TfidfVectorizer(stop_words='english')
        self.item_tfidf_matrix = self.tfidf.fit_transform(
            self.items_df['description'].fillna('')
        )
        
        # Строим матрицу сходства между предметами
        self.item_similarity = cosine_similarity(self.item_tfidf_matrix)
        
        # Если есть данные о рейтингах, можем также построить 
        # коллаборативную модель для не-холодных пользователей
        self.user_item_matrix = None
        if ratings_df is not None:
            self._build_user_item_matrix()
    
    def _build_user_item_matrix(self):
        """Создает разреженную матрицу оценок пользователь-предмет"""
        # Создаем сводную таблицу: строки - пользователи, столбцы - предметы, значения - оценки
        self.user_item_matrix = pd.pivot_table(
            self.ratings_df,
            values='rating',
            index='user_id',
            columns='item_id',
            fill_value=0
        )
        
        # Сохраняем маппинги для быстрого доступа
        self.user_ids = list(self.user_item_matrix.index)
        self.item_ids = list(self.user_item_matrix.columns)
    
    def is_cold_start_user(self, user_id):
        """Проверяет, является ли пользователь холодным (новым)"""
        if self.ratings_df is None:
            return True
        
        return user_id not in self.ratings_df['user_id'].unique()
    
    def is_cold_start_item(self, item_id):
        """Проверяет, является ли предмет холодным (новым)"""
        if self.ratings_df is None:
            return True
        
        return item_id not in self.ratings_df['item_id'].unique()
    
    def get_popular_items(self, n=10):
        """Возвращает самые популярные предметы (для новых пользователей)"""
        if self.ratings_df is None:
            # Если нет данных о рейтингах, возвращаем случайные предметы
            return np.random.choice(self.items_df['item_id'].values, n, replace=False)
        
        # Считаем количество оценок для каждого предмета
        item_popularity = self.ratings_df['item_id'].value_counts()
        
        # Возвращаем топ-N самых популярных предметов
        return item_popularity.nlargest(n).index.tolist()
    
    def get_similar_items(self, item_id, n=10):
        """Находит похожие предметы на основе содержания"""
        # Получаем индекс предмета в матрице сходства
        idx = self.items_df[self.items_df['item_id'] == item_id].index[0]
        
        # Получаем оценки сходства с другими предметами
        item_similarities = self.item_similarity[idx]
        
        # Получаем индексы наиболее похожих предметов (исключая сам предмет)
        similar_indices = np.argsort(-item_similarities)[1:n+1]
        
        # Возвращаем ID похожих предметов
        similar_items = self.items_df.iloc[similar_indices]['item_id'].tolist()
        
        return similar_items
    
    def recommend_for_new_user(self, user_profile=None, n=10):
        """
        Рекомендации для нового пользователя
        
        Параметры:
        - user_profile: словарь с предпочтениями пользователя (например, {'category': 'Книги'})
        - n: количество рекомендаций
        """
        if user_profile is None:
            # Если профиль не указан, возвращаем популярные предметы
            return self.get_popular_items(n)
        
        # Фильтруем предметы по профилю пользователя
        filtered_items = self.items_df.copy()
        for key, value in user_profile.items():
            if key in filtered_items.columns:
                filtered_items = filtered_items[filtered_items[key] == value]
        
        # Если после фильтрации остались предметы, рекомендуем их
        if len(filtered_items) >= n:
            return filtered_items['item_id'].values[:n]
        
        # Иначе дополняем популярными предметами
        remaining = n - len(filtered_items)
        popular_items = self.get_popular_items(remaining)
        
        return np.concatenate([filtered_items['item_id'].values, popular_items])
    
    def recommend_for_existing_user(self, user_id, n=10):
        """Рекомендации для существующего пользователя на основе коллаборативной фильтрации"""
        if self.user_item_matrix is None or user_id not in self.user_ids:
            return self.get_popular_items(n)
        
        # Получаем индекс пользователя
        user_idx = self.user_ids.index(user_id)
        
        # Получаем оценки пользователя
        user_ratings = self.user_item_matrix.iloc[user_idx].values
        
        # Находим предметы, которые пользователь еще не оценил
        unrated_items = np.where(user_ratings == 0)[0]
        
        # Для каждого неоцененного предмета предсказываем оценку
        predicted_ratings = []
        for item_idx in unrated_items:
            item_id = self.item_ids[item_idx]
            
            # Находим похожие предметы, которые пользователь уже оценил
            similar_items = self.get_similar_items(item_id, n=5)
            similar_items_idx = [self.item_ids.index(i) for i in similar_items if i in self.item_ids]
            
            # Если есть похожие предметы с оценками, предсказываем оценку
            if similar_items_idx:
                similar_ratings = user_ratings[similar_items_idx]
                if np.sum(similar_ratings) > 0:
                    predicted_rating = np.mean(similar_ratings[similar_ratings > 0])
                    predicted_ratings.append((item_id, predicted_rating))
        
        # Сортируем предметы по предсказанным оценкам
        predicted_ratings.sort(key=lambda x: x[1], reverse=True)
        
        # Возвращаем топ-N рекомендаций
        return [item_id for item_id, _ in predicted_ratings[:n]]
    
    def recommend(self, user_id=None, user_profile=None, n=10):
        """
        Универсальный метод для получения рекомендаций
        
        Параметры:
        - user_id: ID пользователя (None для нового пользователя)
        - user_profile: профиль пользователя (для нового пользователя)
        - n: количество рекомендаций
        """
        if user_id is None or self.is_cold_start_user(user_id):
            return self.recommend_for_new_user(user_profile, n)
        else:
            return self.recommend_for_existing_user(user_id, n)

# Пример использования
# Создаем синтетические данные
items_df = pd.DataFrame({
    'item_id': range(100),
    'category': np.random.choice(['Электроника', 'Книги', 'Одежда', 'Дом', 'Спорт'], 100),
    'description': [
        f"Этот товар номер {i} относится к категории {cat} и имеет следующие особенности..." 
        for i, cat in enumerate(np.random.choice(['Электроника', 'Книги', 'Одежда', 'Дом', 'Спорт'], 100))
    ]
})

# Создаем данные о рейтингах (500 случайных оценок)
np.random.seed(42)
ratings_data = []
for _ in range(500):
    user_id = np.random.randint(1, 50)  # 50 пользователей
    item_id = np.random.randint(0, 100)  # 100 предметов
    rating = np.random.randint(1, 6)  # оценки от 1 до 5
    ratings_data.append([user_id, item_id, rating])

ratings_df = pd.DataFrame(ratings_data, columns=['user_id', 'item_id', 'rating'])

# Создаем рекомендательную систему
recommender = ColdStartRecommender(items_df, ratings_df)

# Рекомендации для нового пользователя без профиля
print("Рекомендации для нового пользователя (без профиля):")
recommendations = recommender.recommend(user_id=None)
print(recommendations)

# Рекомендации для нового пользователя с профилем
print("\nРекомендации для нового пользователя, который интересуется электроникой:")
user_profile = {'category': 'Электроника'}
recommendations = recommender.recommend(user_id=None, user_profile=user_profile)
print(recommendations)

# Рекомендации для существующего пользователя
existing_user_id = ratings_df['user_id'].iloc[0]
print(f"\nРекомендации для существующего пользователя (ID: {existing_user_id}):")
recommendations = recommender.recommend(user_id=existing_user_id)
print(recommendations)
```

**Что нужно понять из этого задания:**
1. Как определить, является ли пользователь или предмет "холодным"
2. Как использовать разные стратегии для новых и существующих пользователей
3. Как комбинировать контентную фильтрацию и коллаборативную фильтрацию в гибридном подходе
4. Как использовать профиль пользователя для улучшения рекомендаций при холодном старте

## Контекстные рекомендации

Контекстные рекомендательные системы учитывают не только информацию о пользователях и предметах, но и контекст, в котором происходит взаимодействие. Этот контекст может включать время, местоположение, устройство пользователя, предыдущие действия, погоду и многое другое.

### Что такое контекстные рекомендации?

Представь, что ты хочешь порекомендовать фильмы пользователю. Классическая рекомендательная система опирается на историю просмотров и рейтинги. Но контекстная система может учитывать:

- **Время суток**: утром — короткие развлекательные шоу, вечером — полнометражные фильмы
- **День недели**: в будни — сериалы с короткими эпизодами, в выходные — длинные фильмы
- **Сезон**: летом — легкие комедии, зимой — семейные фильмы
- **Устройство**: на мобильном — короткие видео, на ТВ — полноценные фильмы
- **Компания**: один — авторское кино, с семьей — семейные комедии

### Архитектура контекстных рекомендательных систем

Основной подход к контекстным рекомендациям можно разделить на три категории:

1. **Предконтекстное фильтрование (Pre-filtering)**: контекст используется для выбора релевантных данных перед применением обычных методов рекомендаций
2. **Постконтекстное фильтрование (Post-filtering)**: контекст применяется для фильтрации результатов после стандартных рекомендаций
3. **Контекстное моделирование (Contextual modeling)**: контекст непосредственно включается в алгоритм рекомендаций

### Математическая модель

В традиционных рекомендациях мы прогнозируем:
$R: User \times Item \rightarrow Rating$

В контекстных рекомендациях формула расширяется:
$R: User \times Item \times Context \rightarrow Rating$

### Реализация контекстной рекомендательной системы

Давай рассмотрим пример реализации контекстной рекомендательной системы с использованием Factorization Machines (FM) — эффективного метода, который хорошо работает с разреженными данными и может моделировать контекстные факторы:

```python
import numpy as np
import pandas as pd
from sklearn.feature_extraction import DictVectorizer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, Flatten, Multiply, Lambda, Concatenate, Dense
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt

class ContextualRecommender:
    def __init__(self, embedding_size=10):
        """
        Контекстная рекомендательная система на основе Factorization Machines
        
        Параметры:
        - embedding_size: размерность эмбеддингов для пользователей и предметов
        """
        self.embedding_size = embedding_size
        self.model = None
        self.vectorizer = DictVectorizer(sparse=True)
    
    def _prepare_data(self, data):
        """
        Подготавливает данные для FM модели
        
        Параметры:
        - data: DataFrame с колонками user_id, item_id, context_features, rating
                где context_features — словарь контекстных признаков
        """
        # Преобразуем данные в список словарей
        feature_dicts = []
        for _, row in data.iterrows():
            # Создаем словарь с основными признаками
            feature_dict = {
                'user_id': f'user_{row["user_id"]}',
                'item_id': f'item_{row["item_id"]}'
            }
            
            # Добавляем контекстные признаки
            for context_key, context_value in row['context_features'].items():
                feature_dict[f'ctx_{context_key}'] = f'ctx_{context_key}_{context_value}'
            
            feature_dicts.append(feature_dict)
        
        # Векторизуем признаки
        X = self.vectorizer.fit_transform(feature_dicts)
        y = data['rating'].values
        
        return X, y
    
    def _create_model(self, input_dim):
        """Создает модель Factorization Machine"""
        # Входной слой
        input_layer = Input(shape=(input_dim,), sparse=True)
        
        # Линейная часть: bias + w*x
        w0 = tf.Variable(np.zeros(1), name='w0')
        bias = Lambda(lambda x: w0 * tf.ones_like(x)[:,0:1])(input_layer)
        
        w = tf.Variable(np.zeros((input_dim, 1)), name='w')
        linear_term = tf.sparse.sparse_dense_matmul(input_layer, w)
        
        # Нелинейная часть: взаимодействия признаков
        v = tf.Variable(np.random.normal(scale=0.01, size=(input_dim, self.embedding_size)), name='v')
        embeddings = tf.sparse.sparse_dense_matmul(input_layer, v)
        
        # Формула FM: (∑(v_i*x_i))² - ∑(v_i²*x_i²)
        sum_squared = tf.square(embeddings)
        squared_sum = tf.square(tf.sparse.sparse_dense_matmul(tf.square(input_layer), tf.square(v)))
        
        interactions = 0.5 * tf.reduce_sum(sum_squared - squared_sum, 1, keepdims=True)
        
        # Комбинируем все вместе
        output = tf.add_n([bias, linear_term, interactions])
        
        # Создаем и компилируем модель
        model = Model(inputs=input_layer, outputs=output)
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def fit(self, data, epochs=20, batch_size=64, validation_split=0.2):
        """
        Обучает модель на данных
        
        Параметры:
        - data: DataFrame с данными
        - epochs: количество эпох обучения
        - batch_size: размер батча
        - validation_split: доля данных для валидации
        """
        # Подготавливаем данные
        X, y = self._prepare_data(data)
        
        # Создаем модель
        self.model = self._create_model(X.shape[1])
        
        # Разделяем данные на обучающую и валидационную выборки
        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=validation_split, random_state=42)
        
        # Обучаем модель
        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=batch_size,
            verbose=1
        )
        
        return history
    
    def predict(self, user_id, item_id, context_features):
        """
        Предсказывает рейтинг для пары пользователь-предмет с учетом контекста
        
        Параметры:
        - user_id: ID пользователя
        - item_id: ID предмета
        - context_features: словарь контекстных признаков
        """
        # Создаем признаковое представление
        feature_dict = {
            'user_id': f'user_{user_id}',
            'item_id': f'item_{item_id}'
        }
        
        # Добавляем контекстные признаки
        for context_key, context_value in context_features.items():
            feature_dict[f'ctx_{context_key}'] = f'ctx_{context_key}_{context_value}'
        
        # Векторизуем признаки
        X = self.vectorizer.transform([feature_dict])
        
        # Получаем предсказание
        prediction = self.model.predict(X)[0][0]
        
        return prediction
    
    def recommend(self, user_id, available_items, context_features, top_n=10):
        """
        Рекомендует предметы пользователю с учетом контекста
        
        Параметры:
        - user_id: ID пользователя
        - available_items: список доступных предметов
        - context_features: словарь контекстных признаков
        - top_n: количество рекомендаций
        """
        # Предсказываем рейтинги для всех доступных предметов
        predictions = []
        for item_id in available_items:
            predicted_rating = self.predict(user_id, item_id, context_features)
            predictions.append((item_id, predicted_rating))
        
        # Сортируем предметы по предсказанным рейтингам
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        # Возвращаем топ-N рекомендаций
        return predictions[:top_n]

# Пример использования
# Создаем синтетические данные с контекстом
np.random.seed(42)

# Генерируем данные
num_users = 50
num_items = 100
num_interactions = 1000

data = []
for _ in range(num_interactions):
    user_id = np.random.randint(1, num_users + 1)
    item_id = np.random.randint(1, num_items + 1)
    
    # Контекстные признаки
    time_of_day = np.random.choice(['morning', 'afternoon', 'evening', 'night'])
    day_of_week = np.random.choice(['weekday', 'weekend'])
    device = np.random.choice(['mobile', 'tablet', 'desktop', 'tv'])
    
    # Создаем синтетический рейтинг, который зависит от контекста
    base_rating = np.random.normal(3.5, 1.0)  # Базовый рейтинг
    
    # Модификаторы контекста
    time_mod = {'morning': -0.5, 'afternoon': 0, 'evening': 0.5, 'night': 0.2}
    day_mod = {'weekday': -0.2, 'weekend': 0.3}
    device_mod = {'mobile': -0.3, 'tablet': 0, 'desktop': 0.2, 'tv': 0.5}
    
    # Применяем модификаторы
    rating = base_rating + time_mod[time_of_day] + day_mod[day_of_week] + device_mod[device]
    
    # Ограничиваем рейтинг от 1 до 5
    rating = max(1, min(5, rating))
    
    # Добавляем запись
    data.append({
        'user_id': user_id,
        'item_id': item_id,
        'context_features': {
            'time_of_day': time_of_day,
            'day_of_week': day_of_week,
            'device': device
        },
        'rating': rating
    })

# Создаем DataFrame
df = pd.DataFrame(data)

# Создаем и обучаем рекомендательную систему
contextual_recommender = ContextualRecommender(embedding_size=10)
history = contextual_recommender.fit(df, epochs=10)

# Визуализируем процесс обучения
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='Train')
plt.plot(history.history['val_mae'], label='Validation')
plt.title('Mean Absolute Error')
plt.legend()

plt.tight_layout()
plt.show()

# Получаем рекомендации для пользователя в разных контекстах
user_id = 5
available_items = list(range(1, num_items + 1))

# Контекст 1: утро выходного дня на мобильном
context1 = {
    'time_of_day': 'morning',
    'day_of_week': 'weekend',
    'device': 'mobile'
}

# Контекст 2: вечер рабочего дня на телевизоре
context2 = {
    'time_of_day': 'evening',
    'day_of_week': 'weekday',
    'device': 'tv'
}

# Получаем рекомендации
recommendations1 = contextual_recommender.recommend(user_id, available_items, context1, top_n=5)
recommendations2 = contextual_recommender.recommend(user_id, available_items, context2, top_n=5)

print(f"Рекомендации для пользователя {user_id} утром выходного дня на мобильном:")
for i, (item_id, rating) in enumerate(recommendations1, 1):
    print(f"{i}. Предмет {item_id}: {rating:.2f}")

print(f"\nРекомендации для пользователя {user_id} вечером рабочего дня на телевизоре:")
for i, (item_id, rating) in enumerate(recommendations2, 1):
    print(f"{i}. Предмет {item_id}: {rating:.2f}")

# Сравним рекомендации
common_items = set([item for item, _ in recommendations1]) & set([item for item, _ in recommendations2])
print(f"\nКоличество общих предметов в рекомендациях: {len(common_items)} из 5")
```

**Что нужно понять из этого примера:**
1. Как представлять контекстные данные в рекомендательной системе
2. Как модель Factorization Machines учитывает взаимодействия между признаками
3. Как контекст влияет на рекомендации для одного и того же пользователя
4. Почему разные контексты могут приводить к совершенно разным рекомендациям

### Применение контекстных рекомендаций в реальных системах

1. **Музыкальные сервисы**: рекомендуют разную музыку в зависимости от времени дня, активности пользователя и даже погоды
2. **Онлайн-магазины**: меняют рекомендации в зависимости от сезона, локации пользователя и приближающихся праздников
3. **Сервисы доставки еды**: учитывают время суток (завтрак/обед/ужин), погоду и локацию
4. **Стриминговые сервисы**: рекомендуют разный контент в будни/выходные и в зависимости от устройства просмотра

## Рекомендации с мультимодальными данными

Мультимодальные рекомендательные системы используют разные типы данных (или модальности) для улучшения качества рекомендаций. Вместо того чтобы полагаться только на рейтинги или историю взаимодействий, эти системы могут обрабатывать текст, изображения, аудио, видео и другие типы данных.

### Почему мультимодальные данные важны?

Представь, что ты хочешь рекомендовать одежду пользователям интернет-магазина:

1. **Только на основе рейтингов**: если пользователь купил красную футболку и оценил её положительно, мы можем предложить похожие продукты, но не знаем, что именно понравилось — цвет, фасон или материал.

2. **С использованием изображений**: анализируя визуальные признаки, мы можем понять, что пользователю нравятся яркие цвета или определённый стиль.

3. **С учётом текста описаний**: мы можем выявить интерес к конкретным материалам, функциональным особенностям или брендам.

4. **С учётом поведения**: последовательность просмотров и время, проведённое на странице, дают дополнительную информацию о предпочтениях.

Комбинируя эти модальности, мы получаем гораздо более точную картину предпочтений пользователя.

### Архитектуры для мультимодальных рекомендаций

#### 1. Ранняя интеграция (Early Fusion)

В этом подходе разные модальности объединяются на уровне признаков перед подачей в модель рекомендаций:

```
Текстовые данные → Текстовые признаки →
                                      → Объединённые признаки → Модель рекомендаций
Визуальные данные → Визуальные признаки →
```

#### 2. Поздняя интеграция (Late Fusion)

В этом подходе для каждой модальности обучается отдельная модель, а затем их результаты объединяются:

```
Текстовые данные → Текстовая модель → Предсказание 1 →
                                                     → Ансамблирование → Финальное предсказание
Визуальные данные → Визуальная модель → Предсказание 2 →
```

#### 3. Гибридная интеграция (Hybrid Fusion)

Комбинирует преимущества ранней и поздней интеграции:

```
Текстовые данные → Текстовые признаки → Промежуточная модель 1 → Совместное представление → Финальное предсказание
Визуальные данные → Визуальные признаки → Промежуточная модель 2 →
```

### Реализация мультимодальной рекомендательной системы

Давай рассмотрим пример реализации системы рекомендации фильмов, которая использует как текстовые (описания фильмов), так и визуальные данные (постеры):

```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from transformers import TFBertModel, BertTokenizer
import os

class MultimodalRecommender:
    def __init__(self, text_embedding_size=768, image_embedding_size=1280):
        """
        Мультимодальная рекомендательная система
        
        Параметры:
        - text_embedding_size: размерность текстовых эмбеддингов
        - image_embedding_size: размерность визуальных эмбеддингов
        """
        self.text_embedding_size = text_embedding_size
        self.image_embedding_size = image_embedding_size
        
        # Инициализация моделей для извлечения признаков из разных модальностей
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        self.text_model = TFBertModel.from_pretrained('bert-base-uncased')
        self.image_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')
        
        # Основная модель для рекомендаций
        self.recommendation_model = None
    
    def extract_text_features(self, descriptions):
        """Извлекает признаки из текстовых описаний с помощью BERT"""
        # Токенизируем тексты
        inputs = self.tokenizer(
            descriptions, 
            return_tensors='tf', 
            padding=True, 
            truncation=True, 
            max_length=128
        )
        
        # Получаем эмбеддинги от BERT
        outputs = self.text_model(inputs)
        
        # Используем эмбеддинг [CLS] токена как представление всего текста
        return outputs.last_hidden_state[:,0,:].numpy()
    
    def extract_image_features(self, image_paths):
        """Извлекает признаки из изображений с помощью MobileNetV2"""
        features = []
        
        for path in image_paths:
            if os.path.exists(path):
                # Загружаем и предобрабатываем изображение
                img = load_img(path, target_size=(224, 224))
                img_array = img_to_array(img)
                img_array = np.expand_dims(img_array, axis=0)
                img_array = preprocess_input(img_array)
                
                # Извлекаем признаки
                feature = self.image_model.predict(img_array, verbose=0)
                features.append(feature[0])
            else:
                # Если файл не найден, заполняем нулями
                features.append(np.zeros(self.image_embedding_size))
        
        return np.array(features)
    
    def create_model(self, num_users, num_items):
        """Создает мультимодальную модель рекомендаций"""
        # Входные слои
        user_input = Input(shape=(1,), name='user_input')
        item_input = Input(shape=(1,), name='item_input')
        text_input = Input(shape=(self.text_embedding_size,), name='text_input')
        image_input = Input(shape=(self.image_embedding_size,), name='image_input')
        
        # Эмбеддинги пользователей и предметов
        user_embedding = Embedding(num_users, 50, name='user_embedding')(user_input)
        item_embedding = Embedding(num_items, 50, name='item_embedding')(item_input)
        
        # Сглаживаем эмбеддинги
        user_vector = Flatten()(user_embedding)
        item_vector = Flatten()(item_embedding)
        
        # Обрабатываем текстовые признаки
        text_features = Dense(128, activation='relu')(text_input)
        text_features = Dropout(0.3)(text_features)
        
        # Обрабатываем визуальные признаки
        image_features = Dense(128, activation='relu')(image_input)
        image_features = Dropout(0.3)(image_features)
        
        # Объединяем все признаки (ранняя интеграция)
        concat = Concatenate()([user_vector, item_vector, text_features, image_features])
        
        # Полносвязные слои для выявления сложных зависимостей
        fc1 = Dense(256, activation='relu')(concat)
        fc1 = Dropout(0.3)(fc1)
        fc2 = Dense(128, activation='relu')(fc1)
        fc2 = Dropout(0.3)(fc2)
        output = Dense(1, activation='sigmoid')(fc2)
        
        # Создаем модель
        model = Model(
            inputs=[user_input, item_input, text_input, image_input],
            outputs=output
        )
        
        # Компилируем модель
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def prepare_data(self, ratings_df, items_df, image_dir):
        """
        Подготавливает данные для обучения модели
        
        Параметры:
        - ratings_df: DataFrame с оценками (user_id, item_id, rating)
        - items_df: DataFrame с информацией о предметах (item_id, title, description)
        - image_dir: директория с изображениями предметов
        """
        # Извлекаем признаки из текстов
        text_features = self.extract_text_features(items_df['description'].tolist())
        
        # Извлекаем признаки из изображений
        image_paths = [os.path.join(image_dir, f"{item_id}.jpg") for item_id in items_df['item_id']]
        image_features = self.extract_image_features(image_paths)
        
        # Создаем маппинги id -> index для быстрого доступа
        user_mapping = {user_id: i for i, user_id in enumerate(ratings_df['user_id'].unique())}
        item_mapping = {item_id: i for i, item_id in enumerate(items_df['item_id'].unique())}
        
        # Преобразуем id в индексы
        user_indices = ratings_df['user_id'].map(user_mapping).values
        item_indices = ratings_df['item_id'].map(item_mapping).values
        
        # Получаем метки: 1 - положительная оценка (>= 4), 0 - отрицательная
        labels = (ratings_df['rating'] >= 4).astype(int).values
        
        # Получаем признаки предметов
        item_text_features = np.array([text_features[item_mapping[item_id]] for item_id in ratings_df['item_id']])
        item_image_features = np.array([image_features[item_mapping[item_id]] for item_id in ratings_df['item_id']])
        
        # Разбиваем данные на обучающую и тестовую выборки
        train_indices, test_indices = train_test_split(
            np.arange(len(ratings_df)), 
            test_size=0.2, 
            random_state=42
        )
        
        # Формируем данные для обучения
        train_data = [
            user_indices[train_indices],
            item_indices[train_indices],
            item_text_features[train_indices],
            item_image_features[train_indices]
        ]
        train_labels = labels[train_indices]
        
        # Формируем данные для тестирования
        test_data = [
            user_indices[test_indices],
            item_indices[test_indices],
            item_text_features[test_indices],
            item_image_features[test_indices]
        ]
        test_labels = labels[test_indices]
        
        return (train_data, train_labels), (test_data, test_labels), user_mapping, item_mapping
    
    def fit(self, ratings_df, items_df, image_dir, epochs=10, batch_size=64):
        """
        Обучает модель на данных
        
        Параметры:
        - ratings_df: DataFrame с оценками
        - items_df: DataFrame с информацией о предметах
        - image_dir: директория с изображениями предметов
        - epochs: количество эпох обучения
        - batch_size: размер батча
        """
        # Подготавливаем данные
        (train_data, train_labels), (test_data, test_labels), user_mapping, item_mapping = self.prepare_data(
            ratings_df, items_df, image_dir
        )
        
        # Сохраняем маппинги
        self.user_mapping = user_mapping
        self.item_mapping = item_mapping
        self.reverse_user_mapping = {v: k for k, v in user_mapping.items()}
        self.reverse_item_mapping = {v: k for k, v in item_mapping.items()}
        
        # Сохраняем признаки предметов для быстрого доступа
        self.text_features = {
            item_id: text_features 
            for item_id, text_features in zip(items_df['item_id'], self.extract_text_features(items_df['description'].tolist()))
        }
        
        image_paths = [os.path.join(image_dir, f"{item_id}.jpg") for item_id in items_df['item_id']]
        self.image_features = {
            item_id: image_features 
            for item_id, image_features in zip(items_df['item_id'], self.extract_image_features(image_paths))
        }
        
        # Создаем модель
        num_users = len(user_mapping)
        num_items = len(item_mapping)
        self.recommendation_model = self.create_model(num_users, num_items)
        
        # Обучаем модель
        history = self.recommendation_model.fit(
            train_data, train_labels,
            validation_data=(test_data, test_labels),
            epochs=epochs,
            batch_size=batch_size,
            verbose=1
        )
        
        return history
    
    def recommend(self, user_id, top_n=10, exclude_rated=True, ratings_df=None):
        """
        Рекомендует предметы для пользователя
        
        Параметры:
        - user_id: ID пользователя
        - top_n: количество рекомендаций
        - exclude_rated: исключать ли предметы, которые пользователь уже оценил
        - ratings_df: DataFrame с оценками (нужен только если exclude_rated=True)
        """
        if user_id not in self.user_mapping:
            raise ValueError(f"Пользователь с ID {user_id} не найден")
        
        # Получаем индекс пользователя
        user_idx = self.user_mapping[user_id]
        
        # Определяем, какие предметы исключать
        exclude_items = set()
        if exclude_rated and ratings_df is not None:
            user_rated_items = ratings_df[ratings_df['user_id'] == user_id]['item_id'].values
            exclude_items = set(user_rated_items)
        
        # Получаем предсказания для всех предметов
        predictions = []
        for item_id, item_idx in self.item_mapping.items():
            if item_id in exclude_items:
                continue
                
            # Получаем признаки предмета
            text_feature = self.text_features.get(item_id, np.zeros(self.text_embedding_size))
            image_feature = self.image_features.get(item_id, np.zeros(self.image_embedding_size))
            
            # Делаем предсказание
            prediction = self.recommendation_model.predict(
                [
                    np.array([user_idx]), 
                    np.array([item_idx]), 
                    np.array([text_feature]), 
                    np.array([image_feature])
                ],
                verbose=0
            )[0][0]
            
            predictions.append((item_id, prediction))
        
        # Сортируем по убыванию предсказанных оценок
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        # Возвращаем топ-N рекомендаций
        return predictions[:top_n]

# Пример использования (синтетические данные)
# В реальном сценарии мы бы использовали настоящие описания фильмов и постеры

# Создаем синтетические данные
np.random.seed(42)

# Параметры
num_users = 100
num_items = 50
num_ratings = 1000

# Создаем данные о предметах (фильмы)
items_data = []
for i in range(num_items):
    genre = np.random.choice(['action', 'comedy', 'drama', 'horror', 'sci-fi'])
    description = f"This is a {genre} movie about {np.random.choice(['love', 'adventure', 'crime', 'mystery', 'fantasy'])}. " \
                  f"It features {np.random.choice(['exciting', 'dramatic', 'funny', 'scary', 'emotional'])} " \
                  f"scenes and {np.random.choice(['great', 'impressive', 'stunning', 'amazing', 'remarkable'])} " \
                  f"performances by the actors."
    
    items_data.append({
        'item_id': i,
        'title': f"Movie {i}",
        'description': description,
        'genre': genre
    })

items_df = pd.DataFrame(items_data)

# Создаем данные о рейтингах
ratings_data = []
for _ in range(num_ratings):
    user_id = np.random.randint(0, num_users)
    item_id = np.random.randint(0, num_items)
    
    # Пользователям нравятся определенные жанры
    user_preferred_genre = np.random.choice(['action', 'comedy', 'drama', 'horror', 'sci-fi'])
    movie_genre = items_df.loc[items_df['item_id'] == item_id, 'genre'].values[0]
    
    # Если жанр фильма совпадает с предпочтениями пользователя, вероятность высокой оценки выше
    if movie_genre == user_preferred_genre:
        rating = np.random.choice([3, 4, 5], p=[0.2, 0.3, 0.5])
    else:
        rating = np.random.choice([1, 2, 3, 4, 5], p=[0.3, 0.3, 0.2, 0.1, 0.1])
    
    ratings_data.append({
        'user_id': user_id,
        'item_id': item_id,
        'rating': rating
    })

ratings_df = pd.DataFrame(ratings_data)

# Создаем модель мультимодальных рекомендаций
# Примечание: в реальном сценарии нам понадобились бы настоящие изображения
# Но для примера мы будем использовать только текстовые признаки и заглушки для изображений
recommender = MultimodalRecommender()

# Обходим извлечение признаков из изображений для примера
recommender.extract_image_features = lambda paths: np.random.rand(len(paths), recommender.image_embedding_size)

# Обучаем на синтетических данных
history = recommender.fit(ratings_df, items_df, "dummy_images", epochs=5)

# Визуализируем процесс обучения
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

# Получаем рекомендации для пользователя
user_id = 5
recommendations = recommender.recommend(user_id, top_n=5, ratings_df=ratings_df)

print(f"Рекомендации для пользователя {user_id}:")
for i, (item_id, score) in enumerate(recommendations, 1):
    movie = items_df[items_df['item_id'] == item_id].iloc[0]
    print(f"{i}. {movie['title']} (Жанр: {movie['genre']}) - {score:.4f}")
```

**Что нужно понять из этого примера:**
1. Как объединить разные типы данных (текст и изображения) в одной рекомендательной системе
2. Как использовать предобученные модели (BERT для текста, MobileNetV2 для изображений) для извлечения признаков
3. Как реализовать раннюю интеграцию признаков из разных модальностей
4. Как использовать мультимодальную информацию для более точных рекомендаций

### Примеры использования мультимодальных рекомендаций

1. **Рекомендация одежды**: учитывает не только рейтинги, но и визуальный стиль (цвета, фасоны) и описания (материалы, бренды)

2. **Рекомендация ресторанов**: комбинирует данные о рейтингах, фотографиях блюд, текстовых отзывах и геолокации

3. **Рекомендация музыки**: учитывает не только историю прослушиваний, но и аудиофичи (ритм, тональность) и тексты песен

4. **Рекомендация видеоконтента**: анализирует визуальные характеристики (сцены, цветовая гамма), аудио (речь, звуковые эффекты) и метаданные (жанр, описание)

## Многорукие бандиты и проблема исследования-использования

### Проблема исследования-использования (Exploration-Exploitation)

Один из ключевых вызовов в рекомендательных системах — баланс между исследованием новых предметов (exploration) и использованием уже известной информации о предпочтениях пользователя (exploitation).

**Проблема в двух словах:**
- **Эксплуатация (Exploitation)**: Рекомендовать предметы, которые с высокой вероятностью понравятся пользователю на основе известных предпочтений
- **Исследование (Exploration)**: Рекомендовать новые или малоизвестные предметы, чтобы узнать больше о предпочтениях пользователя

Если система слишком сосредоточена на эксплуатации, пользователь будет видеть однообразные рекомендации и может пропустить много интересного контента. Если система слишком много исследует, рекомендации могут быть нерелевантными и раздражать пользователя.

### Что такое многорукие бандиты (Multi-Armed Bandits)?

Многорукие бандиты — это класс задач из теории вероятностей и обучения с подкреплением, который обеспечивает математическую основу для решения проблемы исследования-использования. Название происходит от воображаемого игрового автомата с несколькими рычагами, каждый из которых даёт случайную награду из своего распределения.

В контексте рекомендательных систем:
- **Рычаги (Arms)** — это различные предметы, которые можно рекомендовать
- **Выбор рычага** — это выбор предмета для рекомендации
- **Награда (Reward)** — это положительная реакция пользователя (клик, просмотр, покупка)
- **Стратегия (Policy)** — это способ выбора рычагов (предметов) для максимизации суммарной награды

### Основные стратегии многоруких бандитов

#### 1. ε-greedy (Эпсилон-жадная стратегия)

Самый простой алгоритм:
- С вероятностью ε выбираем случайный предмет (исследование)
- С вероятностью (1-ε) выбираем предмет с наивысшей ожидаемой наградой (эксплуатация)

```python
def epsilon_greedy(items, rewards, epsilon=0.1):
    # Вычисляем средние награды для каждого предмета
    average_rewards = {}
    for item_id, item_rewards in rewards.items():
        if item_rewards:  # Если есть данные о наградах
            average_rewards[item_id] = sum(item_rewards) / len(item_rewards)
        else:
            average_rewards[item_id] = 0.0
    
    # С вероятностью epsilon выбираем случайный предмет
    if np.random.random() < epsilon:
        return np.random.choice(items)
    
    # Иначе выбираем предмет с наивысшей средней наградой
    best_item = max(average_rewards.items(), key=lambda x: x[1])[0]
    return best_item
```

#### 2. UCB (Upper Confidence Bound)

Этот алгоритм учитывает неопределённость в оценках наград, предпочитая предметы, которые либо имеют высокую ожидаемую награду, либо мало исследованы:

```python
def ucb(items, rewards, total_trials):
    scores = {}
    for item_id in items:
        if item_id in rewards and rewards[item_id]:
            # Средняя награда
            avg_reward = sum(rewards[item_id]) / len(rewards[item_id])
            # Количество испытаний этого предмета
            n = len(rewards[item_id])
            # UCB формула: средняя награда + бонус за неопределённость
            scores[item_id] = avg_reward + np.sqrt(2 * np.log(total_trials) / n)
        else:
            # Если предмет не был опробован, даём ему высокий приоритет
            scores[item_id] = float('inf')
    
    # Выбираем предмет с наивысшим UCB-счётом
    best_item = max(scores.items(), key=lambda x: x[1])[0]
    return best_item
```

#### 3. Thompson Sampling (Семплирование Томпсона)

Этот байесовский подход моделирует распределение наград для каждого предмета и семплирует из этого распределения:

```python
def thompson_sampling(items, rewards):
    samples = {}
    for item_id in items:
        # Для бинарных наград используем бета-распределение
        successes = sum(rewards.get(item_id, []))
        failures = len(rewards.get(item_id, [])) - successes
        
        # Добавляем 1 к каждому параметру для избежания вырожденных случаев
        alpha = successes + 1
        beta = failures + 1
        
        # Семплируем из бета-распределения
        samples[item_id] = np.random.beta(alpha, beta)
    
    # Выбираем предмет с наивысшим семплированным значением
    best_item = max(samples.items(), key=lambda x: x[1])[0]
    return best_item
```

### Контекстные бандиты

В реальных рекомендательных системах награда зависит не только от предмета, но и от пользователя, а также от контекста (время, местоположение и т.д.). Контекстные бандиты расширяют классические алгоритмы, учитывая эту информацию.

### Задание №4: Реализация рекомендательной системы с многорукими бандитами

Давай реализуем простую рекомендательную систему с использованием многоруких бандитов и сравним разные стратегии:

```python
import numpy as np
import matplotlib.pyplot as plt

class BanditRecommender:
    def __init__(self, n_items, strategy='epsilon_greedy', epsilon=0.1):
        """
        Рекомендательная система на основе многоруких бандитов
        
        Параметры:
        - n_items: количество предметов
        - strategy: стратегия выбора ('epsilon_greedy', 'ucb', 'thompson')
        - epsilon: параметр для epsilon-greedy стратегии
        """
        self.n_items = n_items
        self.strategy = strategy
        self.epsilon = epsilon
        
        # Для каждого предмета храним историю наград
        self.rewards = {item_id: [] for item_id in range(n_items)}
        self.total_trials = 0
    
    def recommend(self):
        """Рекомендует предмет на основе выбранной стратегии"""
        items = list(range(self.n_items))
        
        if self.strategy == 'random':
            return np.random.choice(items)
        
        elif self.strategy == 'epsilon_greedy':
            return self._epsilon_greedy(items)
        
        elif self.strategy == 'ucb':
            return self._ucb(items)
        
        elif self.strategy == 'thompson':
            return self._thompson_sampling(items)
    
    def _epsilon_greedy(self, items):
        """Реализация epsilon-greedy стратегии"""
        # Вычисляем средние награды
        average_rewards = {}
        for item_id in items:
            if self.rewards[item_id]:
                average_rewards[item_id] = sum(self.rewards[item_id]) / len(self.rewards[item_id])
            else:
                average_rewards[item_id] = 0.0
        
        # С вероятностью epsilon выбираем случайный предмет
        if np.random.random() < self.epsilon:
            return np.random.choice(items)
        
        # Иначе выбираем предмет с наивысшей средней наградой
        if not average_rewards:
            return np.random.choice(items)
        best_item = max(average_rewards.items(), key=lambda x: x[1])[0]
        return best_item
    
    def _ucb(self, items):
        """Реализация UCB стратегии"""
        if self.total_trials == 0:
            return np.random.choice(items)
        
        scores = {}
        for item_id in items:
            if self.rewards[item_id]:
                avg_reward = sum(self.rewards[item_id]) / len(self.rewards[item_id])
                n = len(self.rewards[item_id])
                scores[item_id] = avg_reward + np.sqrt(2 * np.log(self.total_trials) / n)
            else:
                scores[item_id] = float('inf')
        
        best_item = max(scores.items(), key=lambda x: x[1])[0]
        return best_item
    
    def _thompson_sampling(self, items):
        """Реализация Thompson Sampling стратегии"""
        samples = {}
        for item_id in items:
            successes = sum(self.rewards[item_id])
            failures = len(self.rewards[item_id]) - successes
            alpha = successes + 1
            beta = failures + 1
            samples[item_id] = np.random.beta(alpha, beta)
        
        best_item = max(samples.items(), key=lambda x: x[1])[0]
        return best_item
    
    def update(self, item_id, reward):
        """Обновляет историю наград после получения обратной связи"""
        self.rewards[item_id].append(reward)
        self.total_trials += 1

# Симуляция рекомендательной системы
def run_simulation(n_items=10, n_iterations=1000, true_rewards=None):
    """
    Запускает симуляцию рекомендательной системы
    
    Параметры:
    - n_items: количество предметов
    - n_iterations: количество итераций симуляции
    - true_rewards: истинные вероятности наград для каждого предмета
    """
    if true_rewards is None:
        # Создаем "истинные" вероятности получения награды для каждого предмета
        true_rewards = np.random.beta(2, 5, size=n_items)
    
    # Инициализируем рекомендательные системы с разными стратегиями
    recommenders = {
        'Random': BanditRecommender(n_items, 'random'),
        'Epsilon-Greedy': BanditRecommender(n_items, 'epsilon_greedy', epsilon=0.1),
        'UCB': BanditRecommender(n_items, 'ucb'),
        'Thompson Sampling': BanditRecommender(n_items, 'thompson')
    }
    
    # Отслеживаем кумулятивную награду для каждой стратегии
    cumulative_rewards = {name: np.zeros(n_iterations) for name in recommenders}
    average_rewards = {name: np.zeros(n_iterations) for name in recommenders}
    
    # Запускаем симуляцию
    for t in range(n_iterations):
        for name, recommender in recommenders.items():
            # Получаем рекомендацию
            item_id = recommender.recommend()
            
            # Симулируем получение награды (клик/не клик)
            reward = 1 if np.random.random() < true_rewards[item_id] else 0
            
            # Обновляем рекомендатель
            recommender.update(item_id, reward)
            
            # Обновляем кумулятивную и среднюю награду
            if t > 0:
                cumulative_rewards[name][t] = cumulative_rewards[name][t-1] + reward
            else:
                cumulative_rewards[name][t] = reward
            
            average_rewards[name][t] = cumulative_rewards[name][t] / (t + 1)
    
    return cumulative_rewards, average_rewards, true_rewards

# Запускаем симуляцию
np.random.seed(42)
n_items = 10
n_iterations = 1000
cumulative_rewards, average_rewards, true_rewards = run_simulation(n_items, n_iterations)

# Визуализируем результаты
plt.figure(figsize=(15, 5))

# График кумулятивной награды
plt.subplot(1, 2, 1)
for name, rewards in cumulative_rewards.items():
    plt.plot(rewards, label=name)
plt.xlabel('Итерация')
plt.ylabel('Кумулятивная награда')
plt.title('Кумулятивная награда по итерациям')
plt.legend()
plt.grid(True)

# График средней награды
plt.subplot(1, 2, 2)
for name, rewards in average_rewards.items():
    plt.plot(rewards, label=name)
plt.xlabel('Итерация')
plt.ylabel('Средняя награда')
plt.title('Средняя награда по итерациям')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# Выводим итоговые результаты
print("Истинные вероятности наград:")
for i, prob in enumerate(true_rewards):
    print(f"Предмет {i}: {prob:.4f}")

print("\nИтоговые результаты:")
for name, rewards in cumulative_rewards.items():
    final_cumulative = rewards[-1]
    final_average = final_cumulative / n_iterations
    print(f"{name}: Общая награда = {final_cumulative}, Средняя награда = {final_average:.4f}")

# Анализируем частоту выбора каждого предмета для Thompson Sampling
thompson_recommender = BanditRecommender(n_items, 'thompson')
item_counts = np.zeros(n_items)

for _ in range(n_iterations):
    item_id = thompson_recommender.recommend()
    reward = 1 if np.random.random() < true_rewards[item_id] else 0
    thompson_recommender.update(item_id, reward)
    item_counts[item_id] += 1

plt.figure(figsize=(10, 5))
plt.bar(range(n_items), item_counts / n_iterations)
plt.xlabel('Предмет')
plt.ylabel('Частота выбора')
plt.title('Частота выбора каждого предмета (Thompson Sampling)')
plt.xticks(range(n_items))
plt.grid(True, axis='y')
plt.show()
```

**Что нужно понять из этого примера:**
1. Как разные стратегии многоруких бандитов балансируют исследование и использование
2. Почему Thompson Sampling часто показывает лучшие результаты в долгосрочной перспективе
3. Как адаптировать многорукие бандиты для рекомендательных систем

### Применение в реальных рекомендательных системах

Алгоритмы многоруких бандитов широко применяются в промышленных рекомендательных системах:

1. **Netflix** использует контекстные бандиты для выбора обложек фильмов и сериалов
2. **LinkedIn** применяет многорукие бандиты для рекомендации контента в ленте
3. **YouTube** использует контекстные бандиты для рекомендации видео
4. **Amazon** и **Alibaba** применяют различные варианты бандитов для рекомендации товаров

### Преимущества и ограничения

**Преимущества:**
- Автоматически балансируют исследование и использование
- Адаптируются к изменяющимся предпочтениям пользователей
- Не требуют больших объёмов данных для начала работы
- Могут работать в режиме реального времени

**Ограничения:**
- Обычно не учитывают долгосрочное влияние рекомендаций
- Могут застрять в локальных оптимумах
- Часто фокусируются на краткосрочной награде в ущерб разнообразию

## Оценка рекомендательных систем в реальном мире

Оценка эффективности рекомендательных систем — это сложная задача, которая выходит далеко за пределы стандартных метрик машинного обучения. Хорошие рекомендации должны быть не только точными, но и разнообразными, новыми, своевременными и соответствовать бизнес-целям.

### Проблемы оценки рекомендательных систем

1. **Обратная связь только для рекомендованных предметов**
   - Мы не знаем, понравились бы пользователю предметы, которые не были рекомендованы
   - Это создаёт смещение в данных и затрудняет офлайн-оценку
  
2. **Изменение поведения пользователей со временем**
   - Предпочтения пользователей меняются
   - Появляются новые предметы, старые становятся менее релевантными
  
3. **Конфликт метрик**
   - Некоторые метрики могут противоречить друг другу
   - Например, повышение точности часто снижает разнообразие

### Офлайн-метрики оценки

#### Метрики точности прогнозирования рейтингов

Если система предсказывает рейтинги, можно использовать стандартные метрики регрессии:

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error

def rmse(y_true, y_pred):
    """Root Mean Squared Error"""
    return np.sqrt(mean_squared_error(y_true, y_pred))

def mae(y_true, y_pred):
    """Mean Absolute Error"""
    return mean_absolute_error(y_true, y_pred)
```

#### Метрики ранжирования

Если система решает задачу ранжирования, более подходят следующие метрики:

```python
def precision_at_k(actual, predicted, k):
    """Precision at k"""
    if len(predicted) > k:
        predicted = predicted[:k]
    
    num_hits = len(set(actual) & set(predicted))
    return num_hits / k

def recall_at_k(actual, predicted, k):
    """Recall at k"""
    if len(predicted) > k:
        predicted = predicted[:k]
    
    num_hits = len(set(actual) & set(predicted))
    return num_hits / len(actual) if len(actual) > 0 else 0.0

def average_precision(actual, predicted, k=10):
    """Average Precision at k"""
    if not actual:
        return 0.0
    
    if len(predicted) > k:
        predicted = predicted[:k]
    
    score = 0.0
    num_hits = 0.0
    
    for i, p in enumerate(predicted):
        if p in actual:
            num_hits += 1.0
            score += num_hits / (i + 1.0)
    
    return score / min(len(actual), k)

def ndcg_at_k(actual, predicted, k=10):
    """Normalized Discounted Cumulative Gain at k"""
    if not actual:
        return 0.0
    
    # Обрезаем список рекомендаций до k
    if len(predicted) > k:
        predicted = predicted[:k]
    
    # Создаем словарь релевантности
    relevance = {item: 1 for item in actual}
    
    # Вычисляем DCG
    dcg = 0.0
    for i, item in enumerate(predicted):
        if item in relevance:
            # Предполагаем бинарную релевантность (1 если предмет релевантен, 0 если нет)
            dcg += 1.0 / np.log2(i + 2)  # i+2 т.к. log2(1) = 0
    
    # Вычисляем IDCG (идеальный DCG)
    idcg = sum(1.0 / np.log2(i + 2) for i in range(min(len(actual), k)))
    
    return dcg / idcg if idcg > 0 else 0.0
```

#### Метрики разнообразия и новизны

```python
def diversity(recommended_items, item_features):
    """
    Разнообразие рекомендаций
    
    Параметры:
    - recommended_items: список рекомендованных предметов
    - item_features: словарь {item_id: feature_vector}
    """
    if len(recommended_items) <= 1:
        return 0.0
    
    # Вычисляем среднее попарное расстояние между предметами
    sum_distance = 0.0
    count = 0
    
    for i in range(len(recommended_items)):
        for j in range(i+1, len(recommended_items)):
            item_i = recommended_items[i]
            item_j = recommended_items[j]
            
            # Косинусное расстояние (1 - косинусное сходство)
            similarity = np.dot(item_features[item_i], item_features[item_j])
            similarity /= (np.linalg.norm(item_features[item_i]) * np.linalg.norm(item_features[item_j]))
            distance = 1.0 - similarity
            
            sum_distance += distance
            count += 1
    
    return sum_distance / count

def novelty(recommended_items, item_popularity):
    """
    Новизна рекомендаций (непопулярность)
    
    Параметры:
    - recommended_items: список рекомендованных предметов
    - item_popularity: словарь {item_id: популярность}
    """
    if not recommended_items:
        return 0.0
    
    # Вычисляем среднюю непопулярность (неожиданность) рекомендаций
    # Предполагаем, что популярность нормализована (от 0 до 1)
    unexpectedness = sum(1.0 - item_popularity.get(item, 0.0) for item in recommended_items)
    return unexpectedness / len(recommended_items)

def coverage(all_recommended_items, all_items):
    """
    Покрытие каталога (процент предметов, которые были рекомендованы хотя бы раз)
    
    Параметры:
    - all_recommended_items: множество всех предметов, рекомендованных хотя бы раз
    - all_items: множество всех доступных предметов
    """
    return len(all_recommended_items) / len(all_items)
```

### Онлайн-эксперименты (A/B тесты)

В реальном мире наиболее надежным методом оценки рекомендательных систем являются A/B тесты:

1. **Подготовка**: 
   - Определите метрики успеха (CTR, конверсия, время на сайте и т.д.)
   - Выберите размер групп и продолжительность эксперимента
   - Подготовьте инфраструктуру для сбора и анализа данных

2. **Проведение эксперимента**:
   - Случайным образом распределите пользователей по группам
   - Одна группа получает рекомендации от существующей системы (контрольная группа)
   - Другая группа получает рекомендации от новой системы (экспериментальная группа)
   - Собирайте данные о взаимодействиях пользователей

3. **Анализ результатов**:
   - Проверьте статистическую значимость различий
   - Учитывайте долгосрочные эффекты
   - Оценивайте влияние на бизнес-метрики

### Практические рекомендации по оценке

1. **Комбинируйте офлайн и онлайн оценку**
   - Начинайте с офлайн-метрик для быстрого итерирования
   - Проверяйте лучшие модели с помощью A/B тестов

2. **Выбирайте метрики в соответствии с бизнес-целями**
   - Для магазина важнее конверсия и доход
   - Для контентной платформы — вовлеченность и время использования

3. **Не забывайте о долгосрочных эффектах**
   - Оптимизация краткосрочных метрик может негативно повлиять на долгосрочную ценность
   - Отслеживайте удержание пользователей и их удовлетворенность

4. **Используйте сегментацию**
   - Разные группы пользователей могут по-разному реагировать на рекомендации
   - Оценивайте эффективность отдельно для новых и существующих пользователей

## Деплой рекомендательных систем

Внедрение рекомендательных систем в продакшн – это особый вызов, требующий тщательного планирования и инженерных решений. Давайте рассмотрим основные аспекты деплоя и обслуживания рекомендательных систем.

### Архитектурные паттерны для рекомендательных систем

#### 1. Типичная архитектура системы рекомендаций

```
Сбор данных → Обработка данных → Обучение модели → Генерация рекомендаций → Доставка рекомендаций
    ↑                                    ↓
    └────────────────── Обратная связь ──┘
```

#### 2. Онлайн vs Офлайн рекомендации

**Офлайн рекомендации**:
- Рекомендации формируются заранее по расписанию (например, раз в день)
- Преимущества: низкая латентность при выдаче, меньше требований к инфраструктуре
- Недостатки: не учитывают самые свежие действия пользователя

**Онлайн рекомендации**:
- Рекомендации формируются в момент запроса пользователя
- Преимущества: учитывают самые последние действия, можно адаптировать под контекст
- Недостатки: высокие требования к производительности, сложнее масштабировать

#### 3. Гибридный подход

```
[Офлайн] Периодическое обучение моделей и прекомпьютинг рекомендаций
       ↓
[Онлайн] Быстрая корректировка предварительно рассчитанных рекомендаций на основе текущего контекста
```

### Технические аспекты деплоя

#### 1. Масштабирование и производительность

Рекомендательные системы должны обслуживать тысячи или миллионы запросов в секунду с низкой латентностью:

```python
# Пример использования кэширования для ускорения выдачи рекомендаций
import redis
import json

class CachedRecommender:
    def __init__(self, redis_host='localhost', redis_port=6379, expire_time=3600):
        self.cache = redis.Redis(host=redis_host, port=redis_port)
        self.expire_time = expire_time  # Время жизни кэша в секундах
        self.fallback_recommender = None  # Основная рекомендательная система
    
    def set_fallback(self, recommender):
        """Устанавливает основной рекомендатель, используемый при отсутствии кэша"""
        self.fallback_recommender = recommender
    
    def get_recommendations(self, user_id, context=None, n=10):
        """Получает рекомендации для пользователя, используя кэш, если возможно"""
        cache_key = f"rec:{user_id}"
        if context:
            # Если есть контекст, добавляем его к ключу кэша
            context_str = json.dumps(context, sort_keys=True)
            cache_key += f":{context_str}"
        
        # Пытаемся получить рекомендации из кэша
        cached_recs = self.cache.get(cache_key)
        if cached_recs:
            # Если рекомендации найдены в кэше, десериализуем и возвращаем
            return json.loads(cached_recs)
        
        # Если кэш не содержит рекомендаций, используем основной рекомендатель
        if self.fallback_recommender:
            recommendations = self.fallback_recommender.get_recommendations(user_id, context, n)
            
            # Сохраняем результат в кэш
            self.cache.setex(
                cache_key,
                self.expire_time,
                json.dumps(recommendations)
            )
            
            return recommendations
        
        # Если нет fallback, возвращаем пустой список
        return []
```

#### 2. Микросервисная архитектура

Часто рекомендательные системы разделяют на несколько микросервисов:

```
- Сервис сбора данных о пользователях
- Сервис обработки и подготовки признаков
- Сервис обучения моделей
- Сервис генерации рекомендаций
- Сервис доставки рекомендаций
```

#### 3. Мониторинг и обслуживание

```python
# Пример простой системы мониторинга для рекомендательной системы
import time
import logging
from prometheus_client import Counter, Histogram, start_http_server

# Метрики для мониторинга
RECOMMENDATIONS_COUNT = Counter('recommendations_total', 'Total number of recommendations served')
RESPONSE_TIME = Histogram('recommendation_latency_seconds', 'Recommendation service latency in seconds')
ERROR_COUNT = Counter('recommendation_errors_total', 'Total number of recommendation errors')

class MonitoredRecommender:
    def __init__(self, base_recommender):
        self.recommender = base_recommender
        self.logger = logging.getLogger('recommender')
    
    def get_recommendations(self, user_id, context=None, n=10):
        """Обертка для рекомендатора с мониторингом производительности и ошибок"""
        RECOMMENDATIONS_COUNT.inc()
        
        try:
            start_time = time.time()
            recommendations = self.recommender.get_recommendations(user_id, context, n)
            latency = time.time() - start_time
            
            # Записываем метрику латентности
            RESPONSE_TIME.observe(latency)
            
            # Логируем при превышении порога латентности
            if latency > 0.5:  # Латентность > 500 мс
                self.logger.warning(f"High latency ({latency:.2f}s) for user {user_id}")
            
            return recommendations
            
        except Exception as e:
            # Увеличиваем счетчик ошибок
            ERROR_COUNT.inc()
            self.logger.error(f"Error generating recommendations for user {user_id}: {str(e)}")
            
            # Возвращаем резервные рекомендации или пустой список
            return []

# Запускаем HTTP-сервер для сбора метрик (обычно на порту 9090)
start_http_server(9090)
```

### Пример: Бесконечная лента рекомендаций в стиле TikTok

Давайте посмотрим на пример практической реализации системы рекомендаций для бесконечной ленты контента, подобной TikTok:

```python
import numpy as np
import redis
import json
import time
from collections import defaultdict

class InfiniteScrollRecommender:
    def __init__(self, redis_host='localhost', redis_port=6379):
        # Подключение к Redis для хранения истории просмотров и кэширования
        self.redis = redis.Redis(host=redis_host, port=redis_port)
        
        # Симулируем наличие векторных представлений для пользователей и контента
        self.user_embeddings = {}  # Будет заполняться по мере взаимодействия
        self.content_embeddings = {}  # Предполагаем, что у нас есть эмбеддинги для контента
        
        # Индексы для быстрого поиска похожего контента
        self.content_index = None  # В реальности здесь был бы Faiss или подобный индекс
        
        # Отслеживание метрик
        self.metrics = defaultdict(lambda: defaultdict(float))
    
    def record_view(self, user_id, content_id, view_duration, timestamp=None):
        """Записывает событие просмотра контента пользователем"""
        if timestamp is None:
            timestamp = time.time()
        
        # Создаем запись о взаимодействии
        interaction = {
            'user_id': user_id,
            'content_id': content_id,
            'view_duration': view_duration,
            'timestamp': timestamp
        }
        
        # Сохраняем запись в Redis
        # Используем sorted set для хранения истории просмотров с временной меткой как score
        self.redis.zadd(f"user:{user_id}:views", {content_id: timestamp})
        
        # Обновляем счетчик просмотров для контента
        self.redis.zincrby("content:views", 1, content_id)
        
        # Сохраняем длительность просмотра
        view_time_key = f"content:{content_id}:view_time"
        current_total = float(self.redis.get(view_time_key) or 0)
        self.redis.set(view_time_key, current_total + view_duration)
        
        # Логика обновления embeddings пользователя будет здесь
        # Это может быть реализовано через инкрементное обучение модели
        
        return True
    
    def get_recommendations(self, user_id, batch_size=10, exclude_seen=True):
        """Получает следующий пакет рекомендаций для бесконечной ленты"""
        start_time = time.time()
        
        # Получаем историю просмотров пользователя, если нужно исключить увиденное
        seen_content = set()
        if exclude_seen:
            seen_content = set(self.redis.zrange(f"user:{user_id}:views", 0, -1))
        
        # Определяем стратегию рекомендаций
        # Для нового пользователя - популярный контент
        if not self.redis.exists(f"user:{user_id}:views"):
            recommendations = self._get_popular_content(batch_size, seen_content)
        else:
            # Для существующего пользователя комбинируем различные стратегии:
            # 1. Персонализированные рекомендации на основе истории (60%)
            # 2. Популярный контент (20%)
            # 3. Разведка - новый или разнообразный контент (20%)
            
            # Определяем сколько элементов от каждой стратегии
            n_personalized = int(batch_size * 0.6)
            n_popular = int(batch_size * 0.2)
            n_explore = batch_size - n_personalized - n_popular
            
            # Получаем рекомендации по каждой стратегии
            personalized = self._get_personalized_recommendations(user_id, n_personalized, seen_content)
            popular = self._get_popular_content(n_popular, seen_content | set(personalized))
            explore = self._get_explore_content(user_id, n_explore, seen_content | set(personalized) | set(popular))
            
            # Комбинируем и перемешиваем рекомендации
            recommendations = personalized + popular + explore
            np.random.shuffle(recommendations)
        
        # Записываем метрики латентности
        latency = time.time() - start_time
        self.metrics["latency"]["recommendations"] = 0.9 * self.metrics["latency"]["recommendations"] + 0.1 * latency
        
        return recommendations
    
    def _get_popular_content(self, n, exclude_ids=None):
        """Получает популярный контент, исключая указанные ID"""
        if exclude_ids is None:
            exclude_ids = set()
        
        # Получаем популярные элементы из Redis
        popular_content = self.redis.zrevrange("content:views", 0, n + len(exclude_ids) - 1)
        
        # Фильтруем уже просмотренные
        filtered_content = [content_id for content_id in popular_content if content_id not in exclude_ids]
        
        return filtered_content[:n]
    
    def _get_personalized_recommendations(self, user_id, n, exclude_ids=None):
        """Получает персонализированные рекомендации на основе интересов пользователя"""
        if exclude_ids is None:
            exclude_ids = set()
        
        # В реальной системе здесь был бы запрос к модели машинного обучения
        # Для примера используем случайные рекомендации из топ-1000 популярных элементов
        popular = self.redis.zrevrange("content:views", 0, 999)
        
        # Исключаем уже просмотренные
        available = [content_id for content_id in popular if content_id not in exclude_ids]
        
        # Выбираем n случайных элементов
        if len(available) <= n:
            return available
        
        return np.random.choice(available, n, replace=False).tolist()
    
    def _get_explore_content(self, user_id, n, exclude_ids=None):
        """Получает контент для исследования (новый или разнообразный)"""
        if exclude_ids is None:
            exclude_ids = set()
        
        # В реальной системе здесь была бы логика для выбора нового или разнообразного контента
        # Для примера используем наименее популярные элементы
        less_popular = self.redis.zrange("content:views", 0, 1000)
        
        # Исключаем уже просмотренные
        available = [content_id for content_id in less_popular if content_id not in exclude_ids]
        
        # Выбираем n случайных элементов
        if len(available) <= n:
            return available
        
        return np.random.choice(available, n, replace=False).tolist()
    
    def update_user_preferences(self, user_id):
        """Обновляет модель предпочтений пользователя на основе истории просмотров"""
        # В реальной системе здесь было бы инкрементное обучение модели пользователя
        # Для примера просто отмечаем время последнего обновления
        self.redis.set(f"user:{user_id}:last_update", time.time())
    
    def get_metrics(self):
        """Возвращает текущие метрики системы"""
        return dict(self.metrics)
```

### Пример: Система рекомендаций в стиле Tinder

А теперь давайте рассмотрим пример системы рекомендаций для приложения знакомств:

```python
import numpy as np
import redis
import json
import time
from collections import defaultdict

class DatingRecommender:
    def __init__(self, redis_host='localhost', redis_port=6379):
        self.redis = redis.Redis(host=redis_host, port=redis_port)
        
        # Счетчики для мониторинга
        self.request_count = 0
        self.match_count = 0
        
        # Кэши для быстрого доступа
        self.location_index = {}  # Пользователи, индексированные по локации
        self.attribute_index = defaultdict(set)  # Индекс по атрибутам
    
    def register_user(self, user_id, profile_data):
        """Регистрирует нового пользователя в системе рекомендаций"""
        # Сохраняем профиль в Redis
        self.redis.hset(f"user:{user_id}", mapping=profile_data)
        
        # Индексируем пользователя по локации
        location = profile_data.get('location', 'unknown')
        if location not in self.location_index:
            self.location_index[location] = set()
        self.location_index[location].add(user_id)
        
        # Индексируем по атрибутам для быстрого поиска
        for attr, value in profile_data.items():
            if attr not in ['user_id', 'location']:
                self.attribute_index[f"{attr}:{value}"].add(user_id)
        
        return True
    
    def record_interaction(self, user_id, target_id, interaction_type):
        """Записывает взаимодействие между пользователями (лайк, скип и т.д.)"""
        # Сохраняем взаимодействие
        timestamp = time.time()
        
        # Для удобства используем sorted sets с временной меткой как score
        if interaction_type == 'like':
            self.redis.zadd(f"user:{user_id}:likes", {target_id: timestamp})
            
            # Проверяем, есть ли взаимный лайк (матч)
            if self.redis.zscore(f"user:{target_id}:likes", user_id):
                # Регистрируем матч для обоих пользователей
                self.redis.zadd(f"user:{user_id}:matches", {target_id: timestamp})
                self.redis.zadd(f"user:{target_id}:matches", {user_id: timestamp})
                self.match_count += 1
                
                return {"match": True, "target_id": target_id}
        
        elif interaction_type == 'skip':
            self.redis.zadd(f"user:{user_id}:skips", {target_id: timestamp})
        
        # Обновляем счетчики взаимодействий
        self.redis.hincrby(f"user:{user_id}:stats", f"{interaction_type}_count", 1)
        
        return {"match": False}
    
    def get_recommendations(self, user_id, n=10):
        """Получает рекомендации для пользователя"""
        self.request_count += 1
        
        # Получаем данные о пользователе
        user_data = self.redis.hgetall(f"user:{user_id}")
        if not user_data:
            return []  # Пользователь не найден
        
        # Преобразуем из байтов в строки
        user_data = {k.decode(): v.decode() for k, v in user_data.items()}
        
        # Получаем множества пользователей, с которыми уже было взаимодействие
        likes = set(self.redis.zrange(f"user:{user_id}:likes", 0, -1))
        skips = set(self.redis.zrange(f"user:{user_id}:skips", 0, -1))
        matches = set(self.redis.zrange(f"user:{user_id}:matches", 0, -1))
        
        # Объединяем все взаимодействия
        interacted = likes | skips | matches
        
        # Полная стратегия рекомендаций - комбинация нескольких подходов:
        
        # 1. Фильтрация по ключевым критериям (локация, возраст и т.д.)
        location = user_data.get('location', 'unknown')
        potential_matches = self.location_index.get(location, set()).copy()
        
        # Фильтруем по предпочтениям
        interested_in = user_data.get('interested_in', 'any')
        if interested_in != 'any':
            interested_in_users = self.attribute_index.get(f"gender:{interested_in}", set())
            potential_matches &= interested_in_users
        
        # 2. Исключаем пользователей, с которыми уже было взаимодействие
        potential_matches -= set(map(lambda x: x.decode() if isinstance(x, bytes) else x, interacted))
        
        # Исключаем самого пользователя
        potential_matches.discard(user_id)
        
        # 3. Ранжируем по релевантности
        # В реальной системе здесь было бы ML-ранжирование
        # Для примера ранжируем по случайному фактору
        potential_matches = list(potential_matches)
        np.random.shuffle(potential_matches)
        
        # Возвращаем топ N рекомендаций
        recommendations = potential_matches[:n]
        
        # Для каждой рекомендации добавляем базовую информацию
        result = []
        for rec_id in recommendations:
            rec_data = self.redis.hgetall(f"user:{rec_id}")
            rec_data = {k.decode(): v.decode() for k, v in rec_data.items()}
            result.append({
                "user_id": rec_id,
                "name": rec_data.get("name", "Unknown"),
                "age": rec_data.get("age", "Unknown"),
                "gender": rec_data.get("gender", "Unknown"),
                "location": rec_data.get("location", "Unknown"),
                "bio": rec_data.get("bio", "")
            })
        
        return result
    
    def get_stats(self):
        """Возвращает статистику использования системы рекомендаций"""
        return {
            "request_count": self.request_count,
            "match_count": self.match_count,
            "match_rate": self.match_count / max(1, self.request_count)
        }
```

### Ключевые выводы о деплое рекомендательных систем

1. **Производительность критична**: Оптимизируйте систему для быстрой генерации рекомендаций, используйте кэширование и предварительные вычисления
2. **Инженерия данных не менее важна, чем алгоритмы**: Уделите особое внимание сбору, обработке и хранению данных
3. **Мониторинг и метрики**: Отслеживайте не только технические метрики, но и бизнес-показатели
4. **Инкрементное обновление**: Разработайте стратегию обновления моделей без перерывов в обслуживании
5. **Стратегии резервного копирования**: Всегда имейте запасной вариант на случай сбоя основной системы

## Этические аспекты рекомендательных систем

Рекомендательные системы глубоко интегрированы в нашу повседневную жизнь и могут оказывать значительное влияние на поведение и предпочтения людей. Это накладывает серьезную этическую ответственность на разработчиков таких систем.

### Основные этические проблемы

#### 1. Эхо-камеры и фильтрационные пузыри

Термин "эхо-камера" относится к ситуации, когда пользователь видит только тот контент, который соответствует его существующим взглядам, что может усиливать уже имеющиеся убеждения и ограничивать знакомство с альтернативными точками зрения.

```python
def calculate_diversity_score(user_recommendations, category_mapping):
    """Вычисляет разнообразие рекомендаций по категориям"""
    categories = [category_mapping.get(item_id, "unknown") for item_id in user_recommendations]
    unique_categories = set(categories)
    
    # Простейшая метрика - количество уникальных категорий
    diversity_score = len(unique_categories) / len(categories) if categories else 0
    
    return diversity_score
```

#### 2. Систематическое искажение (bias)

Рекомендательные системы могут непреднамеренно усиливать существующие предубеждения и дискриминацию, если данные для обучения содержат эти искажения.

```python
def check_bias_in_recommendations(recommendations, sensitive_attributes, threshold=0.2):
    """
    Проверяет наличие систематического искажения в рекомендациях
    
    Параметры:
    - recommendations: словарь {user_id: [item_id, ...]}
    - sensitive_attributes: словарь {item_id: {"gender": "male/female", "race": "..."}
    - threshold: порог для определения значимого искажения
    """
    # Для каждого атрибута подсчитываем представленность в рекомендациях
    bias_report = {}
    
    for attr_name in next(iter(sensitive_attributes.values())):
        # Собираем все возможные значения атрибута
        attr_values = set(item_attr[attr_name] for item_attr in sensitive_attributes.values())
        
        # Подсчитываем количество рекомендаций для каждого значения атрибута
        attr_counts = {value: 0 for value in attr_values}
        total_count = 0
        
        for user_recs in recommendations.values():
            for item_id in user_recs:
                if item_id in sensitive_attributes:
                    attr_value = sensitive_attributes[item_id][attr_name]
                    attr_counts[attr_value] += 1
                    total_count += 1
        
        # Вычисляем доли и ищем искажения
        if total_count > 0:
            attr_ratios = {value: count / total_count for value, count in attr_counts.items()}
            
            # Находим максимальное отклонение от идеального равномерного распределения
            ideal_ratio = 1.0 / len(attr_values)
            max_deviation = max(abs(ratio - ideal_ratio) for ratio in attr_ratios.values())
            
            bias_report[attr_name] = {
                "ratios": attr_ratios,
                "max_deviation": max_deviation,
                "has_significant_bias": max_deviation > threshold
            }
    
    return bias_report
```

#### 3. Аддиктивное поведение

Рекомендательные системы могут способствовать формированию зависимости от контента, особенно когда они оптимизированы для максимизации вовлеченности.

```python
def detect_addictive_patterns(user_sessions, threshold_hours=4, consecutive_days=3):
    """
    Выявляет пользователей с потенциально аддиктивным поведением
    
    Параметры:
    - user_sessions: словарь {user_id: [{start_time, end_time}, ...]}
    - threshold_hours: порог ежедневного использования в часах
    - consecutive_days: количество дней подряд с превышением порога
    """
    at_risk_users = []
    
    for user_id, sessions in user_sessions.items():
        # Группируем сессии по дням
        daily_usage = defaultdict(float)
        
        for session in sessions:
            # Преобразуем timestamp в дату
            date = datetime.fromtimestamp(session['start_time']).date()
            
            # Вычисляем длительность сессии в часах
            duration_hours = (session['end_time'] - session['start_time']) / 3600
            daily_usage[date] += duration_hours
        
        # Проверяем, есть ли последовательные дни с высоким использованием
        dates = sorted(daily_usage.keys())
        consecutive_high_usage = 0
        max_consecutive = 0
        
        for i in range(len(dates)):
            if daily_usage[dates[i]] >= threshold_hours:
                consecutive_high_usage += 1
                
                # Проверяем, что это последовательный день
                if i > 0 and (dates[i] - dates[i-1]).days == 1:
                    pass  # Продолжаем счетчик
                else:
                    consecutive_high_usage = 1  # Начинаем заново
            else:
                consecutive_high_usage = 0
            
            max_consecutive = max(max_consecutive, consecutive_high_usage)
        
        if max_consecutive >= consecutive_days:
            at_risk_users.append({
                'user_id': user_id,
                'max_consecutive_days': max_consecutive,
                'average_daily_hours': sum(daily_usage.values()) / len(daily_usage)
            })
    
    return at_risk_users
```

#### 4. Манипуляция и скрытое влияние

Рекомендательные системы могут использоваться для манипулирования мнением или поведением пользователей, например, для продвижения определенных политических взглядов или продуктов.

### Стратегии для этичных рекомендательных систем

#### 1. Прозрачность

Пользователи должны понимать, почему им рекомендуется тот или иной контент.

```python
def generate_explanation(user_id, item_id, explanation_type="similar"):
    """
    Генерирует объяснение для рекомендации
    
    Параметры:
    - user_id: ID пользователя
    - item_id: ID рекомендуемого предмета
    - explanation_type: тип объяснения (similar, popular, diverse)
    """
    if explanation_type == "similar":
        # Находим предметы, с которыми пользователь взаимодействовал и которые похожи на рекомендуемый
        user_items = get_user_interacted_items(user_id)
        similar_items = find_similar_items(item_id, user_items)
        
        if similar_items:
            return f"Рекомендуется на основе вашего интереса к {similar_items[0]}"
    
    elif explanation_type == "popular":
        popularity_rank = get_item_popularity_rank(item_id)
        return f"Популярно среди других пользователей (№{popularity_rank} по популярности)"
    
    elif explanation_type == "diverse":
        return "Рекомендуется для расширения ваших интересов"
    
    return "Рекомендовано специально для вас"
```

#### 2. Контроль пользователя

Пользователи должны иметь возможность влиять на то, какие рекомендации они получают.

```python
class UserControlledRecommender:
    def __init__(self):
        self.user_preferences = {}  # {user_id: {"categories": {}, "exclude": set(), ...}}
    
    def set_user_preferences(self, user_id, preferences):
        """Устанавливает предпочтения пользователя для рекомендаций"""
        self.user_preferences[user_id] = preferences
    
    def get_recommendations(self, user_id, n=10):
        """Получает рекомендации с учетом пользовательских предпочтений"""
        # Получаем базовые рекомендации
        base_recommendations = self._get_base_recommendations(user_id)
        
        # Если у пользователя есть предпочтения, применяем их
        if user_id in self.user_preferences:
            preferences = self.user_preferences[user_id]
            
            # Исключаем нежелательные категории или конкретные предметы
            if "exclude" in preferences:
                base_recommendations = [item for item in base_recommendations 
                                       if item not in preferences["exclude"]]
            
            # Применяем предпочтения по категориям
            if "categories" in preferences:
                category_weights = preferences["categories"]
                base_recommendations = self._rerank_by_categories(
                    base_recommendations, category_weights
                )
            
            # Учитываем предпочтения по разнообразию
            if "diversity_level" in preferences:
                diversity_level = preferences["diversity_level"]
                base_recommendations = self._adjust_diversity(
                    base_recommendations, user_id, diversity_level
                )
        
        return base_recommendations[:n]
    
    def _get_base_recommendations(self, user_id):
        """Получает базовые рекомендации без учета пользовательских предпочтений"""
        # Здесь была бы реализация базового рекомендателя
        pass
    
    def _rerank_by_categories(self, recommendations, category_weights):
        """Переранжирует рекомендации с учетом пользовательских весов категорий"""
        # Здесь была бы реализация переранжирования
        pass
    
    def _adjust_diversity(self, recommendations, user_id, diversity_level):
        """Регулирует разнообразие рекомендаций"""
        # Здесь была бы реализация регулирования разнообразия
        pass
```

#### 3. Разнообразие и сбалансированность

Рекомендательные системы должны предлагать разнообразный контент, включая различные точки зрения.

```python
def diversify_recommendations(user_id, base_recommendations, diversity_ratio=0.3):
    """
    Добавляет разнообразие в рекомендации
    
    Параметры:
    - user_id: ID пользователя
    - base_recommendations: базовые персонализированные рекомендации
    - diversity_ratio: доля диверсифицированных рекомендаций
    """
    # Определяем, сколько рекомендаций заменить на более разнообразные
    n_diverse = int(len(base_recommendations) * diversity_ratio)
    n_base = len(base_recommendations) - n_diverse
    
    # Оставляем лучшие персонализированные рекомендации
    personalized_portion = base_recommendations[:n_base]
    
    # Получаем интересы пользователя на основе истории
    user_interests = get_user_interests(user_id)
    
    # Находим категории, которые пользователь редко или никогда не исследовал
    unexplored_categories = find_unexplored_categories(user_interests)
    
    # Получаем рекомендации из неисследованных категорий
    diverse_recommendations = []
    for category in unexplored_categories:
        if len(diverse_recommendations) >= n_diverse:
            break
        
        category_items = get_top_items_in_category(category, exclude=personalized_portion)
        diverse_recommendations.extend(category_items[:n_diverse - len(diverse_recommendations)])
    
    # Комбинируем персонализированные и разнообразные рекомендации
    final_recommendations = personalized_portion + diverse_recommendations
    
    return final_recommendations
```

#### 4. Сознательное проектирование для благополучия пользователей

Рекомендательные системы должны проектироваться с учетом долгосрочного благополучия пользователей, а не только для максимизации краткосрочного вовлечения.

```python
def wellbeing_score(user_stats):
    """
    Вычисляет оценку благополучия пользователя на основе метрик использования
    
    Параметры:
    - user_stats: словарь статистики использования {
        'daily_usage_minutes': [minutes1, minutes2, ...],
        'content_diversity': float, # 0-1
        'social_interactions': int,
        'content_sentiment': float # -1 to 1
      }
    """
    # Проверяем признаки чрезмерного использования
    daily_usage = user_stats.get('daily_usage_minutes', [])
    avg_usage = sum(daily_usage) / len(daily_usage) if daily_usage else 0
    
    # Штраф за чрезмерное использование (более 2 часов в день)
    excessive_usage_penalty = max(0, (avg_usage - 120) / 60)
    
    # Бонус за разнообразный контент
    diversity_bonus = user_stats.get('content_diversity', 0) * 2
    
    # Бонус за социальные взаимодействия
    social_bonus = min(1, user_stats.get('social_interactions', 0) / 10)
    
    # Бонус/штраф за тональность контента
    sentiment_factor = user_stats.get('content_sentiment', 0) * 0.5
    
    # Итоговая оценка благополучия (0-10)
    wellbeing = 5 + diversity_bonus + social_bonus + sentiment_factor - excessive_usage_penalty
    
    return max(0, min(10, wellbeing))
```

### Практические рекомендации для этичных рекомендательных систем

1. **Регулярный аудит на предвзятость**: Проверяйте ваши рекомендации на предмет систематических искажений.

2. **Многоцелевая оптимизация**: Оптимизируйте не только вовлеченность, но и другие метрики, такие как разнообразие, благополучие пользователей, и информативность.

3. **Прозрачность алгоритмов**: Предоставляйте пользователям понятную информацию о том, почему им показывают определенные рекомендации.

4. **Опции настройки для пользователей**: Давайте пользователям контроль над своим опытом и возможность настраивать рекомендации.

5. **Этический кодекс**: Разработайте и следуйте этическому кодексу при проектировании рекомендательных систем.

6. **Разнообразие команды разработчиков**: Включайте в команду людей с различным опытом и происхождением для минимизации слепых пятен.

## Заключение

Рекомендательные системы стали неотъемлемой частью цифрового опыта современного человека. От выбора фильма для просмотра вечером до определения новостей, которые формируют наше представление о мире, эти системы незаметно, но существенно влияют на наши решения и восприятие.

В этом курсе мы рассмотрели основные подходы к созданию рекомендательных систем, от классических методов коллаборативной фильтрации до современных нейросетевых архитектур. Мы обсудили, как решать типичные проблемы — холодный старт, масштабирование, интеграцию разнородных данных, баланс между исследованием и использованием. Мы также коснулись важных аспектов внедрения рекомендательных систем в продакшн и их этической стороны.

Главный вывод: создание эффективной рекомендательной системы — это сбалансированное сочетание технических решений, понимания потребностей пользователей и ответственного подхода к социальному влиянию. 

Будущее рекомендательных систем лежит на пересечении все более глубокого понимания пользователей, возможностей мультимодальных данных и этических принципов, обеспечивающих, что эти системы улучшают жизнь людей, а не манипулируют ими.

Спасибо за внимание к этому курсу, и успехов в создании ваших рекомендательных систем!